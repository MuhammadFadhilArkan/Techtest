{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "14YgHSD22j-kGgHCOpvFAYy9-5F7rsxb4",
      "authorship_tag": "ABX9TyOcPE3mqdtZ44/Si9kre8sM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadFadhilArkan/Techtest/blob/main/Q1/Q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YhZ8Ex2124r"
      },
      "source": [
        "Import Necessary Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuSFirOWpZov"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
        "from datetime import datetime, date\n",
        "from sklearn import preprocessing\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import keras.backend as K\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LSOwaW_162o"
      },
      "source": [
        "Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "cK2uIKqapZfq",
        "outputId": "e2baf3c5-d105-4c24-82e4-cd9db5eef91f"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/CAD IT/Machine Learning Application Engineer Test 2021 V1.1/Q1.csv\")\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>CHP1Temp1(Deg C)</th>\n",
              "      <th>CHP1Temp2(Deg C)</th>\n",
              "      <th>CHP2Temp1(Deg C)</th>\n",
              "      <th>CHP2Temp2(Deg C)</th>\n",
              "      <th>CHP1Vib1(mm/s)</th>\n",
              "      <th>CHP1Vib2(mm/s)</th>\n",
              "      <th>CHP2Vib1(mm/s)</th>\n",
              "      <th>CHP2Vib2(mm/s)</th>\n",
              "      <th>Fault</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3/10/2018 0:00</td>\n",
              "      <td>39.370909</td>\n",
              "      <td>38.637728</td>\n",
              "      <td>40.846605</td>\n",
              "      <td>39.782834</td>\n",
              "      <td>0.060756</td>\n",
              "      <td>0.066139</td>\n",
              "      <td>0.087974</td>\n",
              "      <td>0.097370</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3/10/2018 0:00</td>\n",
              "      <td>39.390616</td>\n",
              "      <td>38.651286</td>\n",
              "      <td>40.884015</td>\n",
              "      <td>39.805669</td>\n",
              "      <td>0.070343</td>\n",
              "      <td>0.064768</td>\n",
              "      <td>0.094204</td>\n",
              "      <td>0.111891</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3/10/2018 0:00</td>\n",
              "      <td>39.403041</td>\n",
              "      <td>38.659552</td>\n",
              "      <td>40.926061</td>\n",
              "      <td>39.817418</td>\n",
              "      <td>0.053073</td>\n",
              "      <td>0.053162</td>\n",
              "      <td>0.085925</td>\n",
              "      <td>0.088741</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3/10/2018 0:00</td>\n",
              "      <td>39.420096</td>\n",
              "      <td>38.677405</td>\n",
              "      <td>40.966947</td>\n",
              "      <td>39.839593</td>\n",
              "      <td>0.059945</td>\n",
              "      <td>0.061724</td>\n",
              "      <td>0.088830</td>\n",
              "      <td>0.100587</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3/10/2018 0:00</td>\n",
              "      <td>39.430529</td>\n",
              "      <td>38.678065</td>\n",
              "      <td>41.008001</td>\n",
              "      <td>39.849687</td>\n",
              "      <td>0.072104</td>\n",
              "      <td>0.060607</td>\n",
              "      <td>0.089137</td>\n",
              "      <td>0.106438</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13842</th>\n",
              "      <td>10/17/2018 15:31</td>\n",
              "      <td>39.781958</td>\n",
              "      <td>39.366774</td>\n",
              "      <td>35.699109</td>\n",
              "      <td>34.977640</td>\n",
              "      <td>1.487568</td>\n",
              "      <td>1.888282</td>\n",
              "      <td>1.005966</td>\n",
              "      <td>1.792363</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13843</th>\n",
              "      <td>10/17/2018 15:32</td>\n",
              "      <td>39.628272</td>\n",
              "      <td>39.461169</td>\n",
              "      <td>35.665838</td>\n",
              "      <td>35.052602</td>\n",
              "      <td>1.489291</td>\n",
              "      <td>1.752119</td>\n",
              "      <td>1.001954</td>\n",
              "      <td>1.742410</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13844</th>\n",
              "      <td>10/17/2018 15:32</td>\n",
              "      <td>39.612208</td>\n",
              "      <td>39.890494</td>\n",
              "      <td>35.971746</td>\n",
              "      <td>34.636423</td>\n",
              "      <td>1.482300</td>\n",
              "      <td>1.850078</td>\n",
              "      <td>1.018153</td>\n",
              "      <td>1.804849</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13845</th>\n",
              "      <td>10/17/2018 15:45</td>\n",
              "      <td>39.822699</td>\n",
              "      <td>39.725013</td>\n",
              "      <td>35.558900</td>\n",
              "      <td>34.845422</td>\n",
              "      <td>1.528402</td>\n",
              "      <td>1.937668</td>\n",
              "      <td>0.818741</td>\n",
              "      <td>1.351930</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13846</th>\n",
              "      <td>10/17/2018 15:45</td>\n",
              "      <td>39.552752</td>\n",
              "      <td>40.011008</td>\n",
              "      <td>35.570325</td>\n",
              "      <td>35.247537</td>\n",
              "      <td>1.521452</td>\n",
              "      <td>1.864466</td>\n",
              "      <td>0.813967</td>\n",
              "      <td>1.312562</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13847 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Timestamp  CHP1Temp1(Deg C)  ...  CHP2Vib2(mm/s)  Fault\n",
              "0        3/10/2018 0:00         39.370909  ...        0.097370      0\n",
              "1        3/10/2018 0:00         39.390616  ...        0.111891      0\n",
              "2        3/10/2018 0:00         39.403041  ...        0.088741      0\n",
              "3        3/10/2018 0:00         39.420096  ...        0.100587      0\n",
              "4        3/10/2018 0:00         39.430529  ...        0.106438      0\n",
              "...                 ...               ...  ...             ...    ...\n",
              "13842  10/17/2018 15:31         39.781958  ...        1.792363      1\n",
              "13843  10/17/2018 15:32         39.628272  ...        1.742410      1\n",
              "13844  10/17/2018 15:32         39.612208  ...        1.804849      1\n",
              "13845  10/17/2018 15:45         39.822699  ...        1.351930      1\n",
              "13846  10/17/2018 15:45         39.552752  ...        1.312562      1\n",
              "\n",
              "[13847 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoU1IdBX2AUe"
      },
      "source": [
        "Check dataset column information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KttHjtzEpZaI",
        "outputId": "1142842c-d477-45cb-8153-9811f0295de2"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13847 entries, 0 to 13846\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   Timestamp         13847 non-null  object \n",
            " 1   CHP1Temp1(Deg C)  13847 non-null  float64\n",
            " 2   CHP1Temp2(Deg C)  13847 non-null  float64\n",
            " 3   CHP2Temp1(Deg C)  13847 non-null  float64\n",
            " 4   CHP2Temp2(Deg C)  13847 non-null  float64\n",
            " 5   CHP1Vib1(mm/s)    13847 non-null  float64\n",
            " 6   CHP1Vib2(mm/s)    13847 non-null  float64\n",
            " 7   CHP2Vib1(mm/s)    13847 non-null  float64\n",
            " 8   CHP2Vib2(mm/s)    13847 non-null  float64\n",
            " 9   Fault             13847 non-null  int64  \n",
            "dtypes: float64(8), int64(1), object(1)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_qnV4Qc2FNQ"
      },
      "source": [
        "Check data distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "ikt6wOc6pZVw",
        "outputId": "628d57c0-fe14-44cb-9b76-1c546c8755b7"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CHP1Temp1(Deg C)</th>\n",
              "      <th>CHP1Temp2(Deg C)</th>\n",
              "      <th>CHP2Temp1(Deg C)</th>\n",
              "      <th>CHP2Temp2(Deg C)</th>\n",
              "      <th>CHP1Vib1(mm/s)</th>\n",
              "      <th>CHP1Vib2(mm/s)</th>\n",
              "      <th>CHP2Vib1(mm/s)</th>\n",
              "      <th>CHP2Vib2(mm/s)</th>\n",
              "      <th>Fault</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13847.000000</td>\n",
              "      <td>13847.000000</td>\n",
              "      <td>13847.000000</td>\n",
              "      <td>13847.000000</td>\n",
              "      <td>13847.000000</td>\n",
              "      <td>13847.000000</td>\n",
              "      <td>13847.000000</td>\n",
              "      <td>13847.000000</td>\n",
              "      <td>13847.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>38.894831</td>\n",
              "      <td>38.372753</td>\n",
              "      <td>37.049863</td>\n",
              "      <td>37.083295</td>\n",
              "      <td>0.998612</td>\n",
              "      <td>1.345662</td>\n",
              "      <td>0.934057</td>\n",
              "      <td>1.763645</td>\n",
              "      <td>0.393082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.657766</td>\n",
              "      <td>1.818556</td>\n",
              "      <td>2.927990</td>\n",
              "      <td>3.476318</td>\n",
              "      <td>0.616521</td>\n",
              "      <td>0.853053</td>\n",
              "      <td>0.619965</td>\n",
              "      <td>1.268073</td>\n",
              "      <td>0.488452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>34.272883</td>\n",
              "      <td>33.652465</td>\n",
              "      <td>31.602933</td>\n",
              "      <td>31.247236</td>\n",
              "      <td>0.046510</td>\n",
              "      <td>0.045864</td>\n",
              "      <td>0.068607</td>\n",
              "      <td>0.082864</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>38.336334</td>\n",
              "      <td>37.233618</td>\n",
              "      <td>35.394773</td>\n",
              "      <td>34.523069</td>\n",
              "      <td>0.070278</td>\n",
              "      <td>0.067707</td>\n",
              "      <td>0.091273</td>\n",
              "      <td>0.108075</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>39.569812</td>\n",
              "      <td>39.364623</td>\n",
              "      <td>38.227170</td>\n",
              "      <td>37.395959</td>\n",
              "      <td>1.322656</td>\n",
              "      <td>1.778066</td>\n",
              "      <td>0.935697</td>\n",
              "      <td>1.670248</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>39.970923</td>\n",
              "      <td>39.671286</td>\n",
              "      <td>39.413810</td>\n",
              "      <td>40.465354</td>\n",
              "      <td>1.473305</td>\n",
              "      <td>1.967611</td>\n",
              "      <td>1.525421</td>\n",
              "      <td>2.952790</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>41.325293</td>\n",
              "      <td>40.638881</td>\n",
              "      <td>43.187444</td>\n",
              "      <td>41.962697</td>\n",
              "      <td>1.610700</td>\n",
              "      <td>2.390570</td>\n",
              "      <td>1.785126</td>\n",
              "      <td>3.950299</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       CHP1Temp1(Deg C)  CHP1Temp2(Deg C)  ...  CHP2Vib2(mm/s)         Fault\n",
              "count      13847.000000      13847.000000  ...    13847.000000  13847.000000\n",
              "mean          38.894831         38.372753  ...        1.763645      0.393082\n",
              "std            1.657766          1.818556  ...        1.268073      0.488452\n",
              "min           34.272883         33.652465  ...        0.082864      0.000000\n",
              "25%           38.336334         37.233618  ...        0.108075      0.000000\n",
              "50%           39.569812         39.364623  ...        1.670248      0.000000\n",
              "75%           39.970923         39.671286  ...        2.952790      1.000000\n",
              "max           41.325293         40.638881  ...        3.950299      1.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCRvcf1k2LBZ"
      },
      "source": [
        "Check for missing value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8J8Igikq3Z5",
        "outputId": "8886a3ad-112a-4773-9559-9b1702ee0b95"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Timestamp           0\n",
              "CHP1Temp1(Deg C)    0\n",
              "CHP1Temp2(Deg C)    0\n",
              "CHP2Temp1(Deg C)    0\n",
              "CHP2Temp2(Deg C)    0\n",
              "CHP1Vib1(mm/s)      0\n",
              "CHP1Vib2(mm/s)      0\n",
              "CHP2Vib1(mm/s)      0\n",
              "CHP2Vib2(mm/s)      0\n",
              "Fault               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE4QH221rNEk"
      },
      "source": [
        "columns =df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVvZ85aJ2Qh7"
      },
      "source": [
        "As we can see, the value of temperature is much higher than vibration, So we need to normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "MbhrwlyXq3VR",
        "outputId": "36bdd02e-bd36-4887-a83e-609fee7f87ce"
      },
      "source": [
        "#Normalize Data\n",
        "X_Scaler = MinMaxScaler()\n",
        "df[columns[1:-1]] = X_Scaler.fit_transform(df[columns[1:-1]])\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>CHP1Temp1(Deg C)</th>\n",
              "      <th>CHP1Temp2(Deg C)</th>\n",
              "      <th>CHP2Temp1(Deg C)</th>\n",
              "      <th>CHP2Temp2(Deg C)</th>\n",
              "      <th>CHP1Vib1(mm/s)</th>\n",
              "      <th>CHP1Vib2(mm/s)</th>\n",
              "      <th>CHP2Vib1(mm/s)</th>\n",
              "      <th>CHP2Vib2(mm/s)</th>\n",
              "      <th>Fault</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3/10/2018 0:00</td>\n",
              "      <td>0.722877</td>\n",
              "      <td>0.713565</td>\n",
              "      <td>0.797934</td>\n",
              "      <td>0.796568</td>\n",
              "      <td>0.009108</td>\n",
              "      <td>0.008647</td>\n",
              "      <td>0.011283</td>\n",
              "      <td>0.003751</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3/10/2018 0:00</td>\n",
              "      <td>0.725672</td>\n",
              "      <td>0.715506</td>\n",
              "      <td>0.801163</td>\n",
              "      <td>0.798699</td>\n",
              "      <td>0.015237</td>\n",
              "      <td>0.008062</td>\n",
              "      <td>0.014912</td>\n",
              "      <td>0.007505</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3/10/2018 0:00</td>\n",
              "      <td>0.727433</td>\n",
              "      <td>0.716689</td>\n",
              "      <td>0.804793</td>\n",
              "      <td>0.799796</td>\n",
              "      <td>0.004196</td>\n",
              "      <td>0.003113</td>\n",
              "      <td>0.010089</td>\n",
              "      <td>0.001520</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3/10/2018 0:00</td>\n",
              "      <td>0.729852</td>\n",
              "      <td>0.719244</td>\n",
              "      <td>0.808322</td>\n",
              "      <td>0.801865</td>\n",
              "      <td>0.008589</td>\n",
              "      <td>0.006764</td>\n",
              "      <td>0.011781</td>\n",
              "      <td>0.004583</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3/10/2018 0:00</td>\n",
              "      <td>0.731331</td>\n",
              "      <td>0.719339</td>\n",
              "      <td>0.811866</td>\n",
              "      <td>0.802807</td>\n",
              "      <td>0.016362</td>\n",
              "      <td>0.006288</td>\n",
              "      <td>0.011960</td>\n",
              "      <td>0.006096</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13842</th>\n",
              "      <td>10/17/2018 15:31</td>\n",
              "      <td>0.781162</td>\n",
              "      <td>0.817917</td>\n",
              "      <td>0.353591</td>\n",
              "      <td>0.348133</td>\n",
              "      <td>0.921281</td>\n",
              "      <td>0.785778</td>\n",
              "      <td>0.546081</td>\n",
              "      <td>0.442024</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13843</th>\n",
              "      <td>10/17/2018 15:32</td>\n",
              "      <td>0.759370</td>\n",
              "      <td>0.831428</td>\n",
              "      <td>0.350719</td>\n",
              "      <td>0.355129</td>\n",
              "      <td>0.922382</td>\n",
              "      <td>0.727705</td>\n",
              "      <td>0.543744</td>\n",
              "      <td>0.429108</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13844</th>\n",
              "      <td>10/17/2018 15:32</td>\n",
              "      <td>0.757092</td>\n",
              "      <td>0.892880</td>\n",
              "      <td>0.377125</td>\n",
              "      <td>0.316289</td>\n",
              "      <td>0.917913</td>\n",
              "      <td>0.769484</td>\n",
              "      <td>0.553181</td>\n",
              "      <td>0.445252</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13845</th>\n",
              "      <td>10/17/2018 15:45</td>\n",
              "      <td>0.786939</td>\n",
              "      <td>0.869194</td>\n",
              "      <td>0.341488</td>\n",
              "      <td>0.335794</td>\n",
              "      <td>0.947386</td>\n",
              "      <td>0.806841</td>\n",
              "      <td>0.437009</td>\n",
              "      <td>0.328142</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13846</th>\n",
              "      <td>10/17/2018 15:45</td>\n",
              "      <td>0.748662</td>\n",
              "      <td>0.910129</td>\n",
              "      <td>0.342474</td>\n",
              "      <td>0.373320</td>\n",
              "      <td>0.942943</td>\n",
              "      <td>0.775620</td>\n",
              "      <td>0.434228</td>\n",
              "      <td>0.317962</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13847 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Timestamp  CHP1Temp1(Deg C)  ...  CHP2Vib2(mm/s)  Fault\n",
              "0        3/10/2018 0:00          0.722877  ...        0.003751      0\n",
              "1        3/10/2018 0:00          0.725672  ...        0.007505      0\n",
              "2        3/10/2018 0:00          0.727433  ...        0.001520      0\n",
              "3        3/10/2018 0:00          0.729852  ...        0.004583      0\n",
              "4        3/10/2018 0:00          0.731331  ...        0.006096      0\n",
              "...                 ...               ...  ...             ...    ...\n",
              "13842  10/17/2018 15:31          0.781162  ...        0.442024      1\n",
              "13843  10/17/2018 15:32          0.759370  ...        0.429108      1\n",
              "13844  10/17/2018 15:32          0.757092  ...        0.445252      1\n",
              "13845  10/17/2018 15:45          0.786939  ...        0.328142      1\n",
              "13846  10/17/2018 15:45          0.748662  ...        0.317962      1\n",
              "\n",
              "[13847 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D4mlFwt2h5d"
      },
      "source": [
        "Check the label distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU0pdjkCtsHs",
        "outputId": "6a338aa3-a0ff-4076-9648-663a0c21ea6f"
      },
      "source": [
        "print(f\"Value counts for each class:\\n\\n{df.Fault.value_counts()}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value counts for each class:\n",
            "\n",
            "0    8404\n",
            "1    5443\n",
            "Name: Fault, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n_1dEy22riC"
      },
      "source": [
        "As we can see, this is an unbalanced dataset, so we need to do the train_test split correctly, and use f1 score for the metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmUJsACu29od"
      },
      "source": [
        "Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_135WKlZq3R2"
      },
      "source": [
        "def create_model():\n",
        "    tf.keras.backend.clear_session()\n",
        "    tf.random.set_seed(49)\n",
        "    np.random.seed(49)\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(units=256,input_shape=[8], activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftbUacea3B9A"
      },
      "source": [
        "Create dataset pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-fTqjh2q28B"
      },
      "source": [
        "y = df[columns[-1]]\n",
        "y = np.asarray(y).astype('float32')\n",
        "y = y.reshape(-1,1)\n",
        "X = df[columns[1:-1]].values\n",
        "X = np.asarray(X).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2_bbODBEqs4"
      },
      "source": [
        "Split the data using stratify to balanced the split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4sh8FhUtQ4S"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmsfeMFbvTID"
      },
      "source": [
        "batch_size = 100\n",
        "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_data = train_data.shuffle(X_train.shape[0]).batch(batch_size)\n",
        "val_data = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "val_data = val_data.batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFrFrl-63HO7"
      },
      "source": [
        "Train the model using learning rate scheduler so that we can use the best learning rate later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnUOyFxFq21x",
        "outputId": "2a875aa3-4048-4870-9e99-6647036b3dd1"
      },
      "source": [
        "METRICS = [\n",
        "           tf.keras.metrics.BinaryAccuracy(name='accuracy', \n",
        "                                           threshold=0.5),\n",
        "          ]\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-8 * 10**(epoch / 100))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=1e-8, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.compile(optimizer=optimizer,                                                   \n",
        "                loss=tf.keras.losses.Huber(),\n",
        "                metrics=METRICS)\n",
        "\n",
        "history = model.fit(train_data,batch_size=100,\n",
        "                      epochs=500,validation_data=val_data, callbacks=[lr_schedule])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               2304      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,521\n",
            "Trainable params: 43,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "111/111 [==============================] - 2s 5ms/step - loss: 0.2063 - accuracy: 0.6069 - val_loss: 0.2062 - val_accuracy: 0.6069 - lr: 1.0000e-08\n",
            "Epoch 2/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2063 - accuracy: 0.6069 - val_loss: 0.2062 - val_accuracy: 0.6069 - lr: 1.0233e-08\n",
            "Epoch 3/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2062 - accuracy: 0.6069 - val_loss: 0.2061 - val_accuracy: 0.6069 - lr: 1.0471e-08\n",
            "Epoch 4/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2062 - accuracy: 0.6069 - val_loss: 0.2061 - val_accuracy: 0.6069 - lr: 1.0715e-08\n",
            "Epoch 5/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2061 - accuracy: 0.6069 - val_loss: 0.2060 - val_accuracy: 0.6069 - lr: 1.0965e-08\n",
            "Epoch 6/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2061 - accuracy: 0.6069 - val_loss: 0.2060 - val_accuracy: 0.6069 - lr: 1.1220e-08\n",
            "Epoch 7/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2060 - accuracy: 0.6069 - val_loss: 0.2059 - val_accuracy: 0.6069 - lr: 1.1482e-08\n",
            "Epoch 8/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2060 - accuracy: 0.6069 - val_loss: 0.2059 - val_accuracy: 0.6069 - lr: 1.1749e-08\n",
            "Epoch 9/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2059 - accuracy: 0.6069 - val_loss: 0.2058 - val_accuracy: 0.6069 - lr: 1.2023e-08\n",
            "Epoch 10/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2059 - accuracy: 0.6069 - val_loss: 0.2058 - val_accuracy: 0.6069 - lr: 1.2303e-08\n",
            "Epoch 11/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2058 - accuracy: 0.6069 - val_loss: 0.2057 - val_accuracy: 0.6069 - lr: 1.2589e-08\n",
            "Epoch 12/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2058 - accuracy: 0.6069 - val_loss: 0.2057 - val_accuracy: 0.6069 - lr: 1.2882e-08\n",
            "Epoch 13/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2057 - accuracy: 0.6069 - val_loss: 0.2056 - val_accuracy: 0.6069 - lr: 1.3183e-08\n",
            "Epoch 14/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2056 - accuracy: 0.6069 - val_loss: 0.2055 - val_accuracy: 0.6069 - lr: 1.3490e-08\n",
            "Epoch 15/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2056 - accuracy: 0.6069 - val_loss: 0.2055 - val_accuracy: 0.6069 - lr: 1.3804e-08\n",
            "Epoch 16/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2055 - accuracy: 0.6069 - val_loss: 0.2054 - val_accuracy: 0.6069 - lr: 1.4125e-08\n",
            "Epoch 17/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2055 - accuracy: 0.6069 - val_loss: 0.2054 - val_accuracy: 0.6069 - lr: 1.4454e-08\n",
            "Epoch 18/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.6069 - val_loss: 0.2053 - val_accuracy: 0.6069 - lr: 1.4791e-08\n",
            "Epoch 19/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2053 - accuracy: 0.6069 - val_loss: 0.2052 - val_accuracy: 0.6069 - lr: 1.5136e-08\n",
            "Epoch 20/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2053 - accuracy: 0.6069 - val_loss: 0.2052 - val_accuracy: 0.6069 - lr: 1.5488e-08\n",
            "Epoch 21/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2052 - accuracy: 0.6069 - val_loss: 0.2051 - val_accuracy: 0.6069 - lr: 1.5849e-08\n",
            "Epoch 22/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2051 - accuracy: 0.6069 - val_loss: 0.2050 - val_accuracy: 0.6069 - lr: 1.6218e-08\n",
            "Epoch 23/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.6069 - val_loss: 0.2050 - val_accuracy: 0.6069 - lr: 1.6596e-08\n",
            "Epoch 24/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2050 - accuracy: 0.6069 - val_loss: 0.2049 - val_accuracy: 0.6069 - lr: 1.6982e-08\n",
            "Epoch 25/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2049 - accuracy: 0.6069 - val_loss: 0.2048 - val_accuracy: 0.6069 - lr: 1.7378e-08\n",
            "Epoch 26/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2049 - accuracy: 0.6069 - val_loss: 0.2048 - val_accuracy: 0.6069 - lr: 1.7783e-08\n",
            "Epoch 27/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2048 - accuracy: 0.6069 - val_loss: 0.2047 - val_accuracy: 0.6069 - lr: 1.8197e-08\n",
            "Epoch 28/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2047 - accuracy: 0.6069 - val_loss: 0.2046 - val_accuracy: 0.6069 - lr: 1.8621e-08\n",
            "Epoch 29/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2046 - accuracy: 0.6069 - val_loss: 0.2046 - val_accuracy: 0.6069 - lr: 1.9055e-08\n",
            "Epoch 30/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2046 - accuracy: 0.6069 - val_loss: 0.2045 - val_accuracy: 0.6069 - lr: 1.9498e-08\n",
            "Epoch 31/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2045 - accuracy: 0.6069 - val_loss: 0.2044 - val_accuracy: 0.6069 - lr: 1.9953e-08\n",
            "Epoch 32/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2044 - accuracy: 0.6069 - val_loss: 0.2043 - val_accuracy: 0.6069 - lr: 2.0417e-08\n",
            "Epoch 33/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2043 - accuracy: 0.6069 - val_loss: 0.2042 - val_accuracy: 0.6069 - lr: 2.0893e-08\n",
            "Epoch 34/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2042 - accuracy: 0.6069 - val_loss: 0.2041 - val_accuracy: 0.6069 - lr: 2.1380e-08\n",
            "Epoch 35/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2041 - accuracy: 0.6069 - val_loss: 0.2040 - val_accuracy: 0.6069 - lr: 2.1878e-08\n",
            "Epoch 36/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2040 - accuracy: 0.6069 - val_loss: 0.2039 - val_accuracy: 0.6069 - lr: 2.2387e-08\n",
            "Epoch 37/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2039 - accuracy: 0.6069 - val_loss: 0.2039 - val_accuracy: 0.6069 - lr: 2.2909e-08\n",
            "Epoch 38/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2038 - accuracy: 0.6069 - val_loss: 0.2038 - val_accuracy: 0.6069 - lr: 2.3442e-08\n",
            "Epoch 39/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2037 - accuracy: 0.6069 - val_loss: 0.2037 - val_accuracy: 0.6069 - lr: 2.3988e-08\n",
            "Epoch 40/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2036 - accuracy: 0.6069 - val_loss: 0.2036 - val_accuracy: 0.6069 - lr: 2.4547e-08\n",
            "Epoch 41/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2035 - accuracy: 0.6069 - val_loss: 0.2035 - val_accuracy: 0.6069 - lr: 2.5119e-08\n",
            "Epoch 42/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2034 - accuracy: 0.6069 - val_loss: 0.2034 - val_accuracy: 0.6069 - lr: 2.5704e-08\n",
            "Epoch 43/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2033 - accuracy: 0.6069 - val_loss: 0.2032 - val_accuracy: 0.6069 - lr: 2.6303e-08\n",
            "Epoch 44/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2032 - accuracy: 0.6069 - val_loss: 0.2031 - val_accuracy: 0.6069 - lr: 2.6915e-08\n",
            "Epoch 45/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2031 - accuracy: 0.6069 - val_loss: 0.2030 - val_accuracy: 0.6069 - lr: 2.7542e-08\n",
            "Epoch 46/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2030 - accuracy: 0.6069 - val_loss: 0.2029 - val_accuracy: 0.6069 - lr: 2.8184e-08\n",
            "Epoch 47/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2029 - accuracy: 0.6069 - val_loss: 0.2028 - val_accuracy: 0.6069 - lr: 2.8840e-08\n",
            "Epoch 48/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2027 - accuracy: 0.6069 - val_loss: 0.2027 - val_accuracy: 0.6069 - lr: 2.9512e-08\n",
            "Epoch 49/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2026 - accuracy: 0.6069 - val_loss: 0.2025 - val_accuracy: 0.6069 - lr: 3.0200e-08\n",
            "Epoch 50/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2025 - accuracy: 0.6069 - val_loss: 0.2024 - val_accuracy: 0.6069 - lr: 3.0903e-08\n",
            "Epoch 51/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2024 - accuracy: 0.6069 - val_loss: 0.2023 - val_accuracy: 0.6069 - lr: 3.1623e-08\n",
            "Epoch 52/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2022 - accuracy: 0.6069 - val_loss: 0.2022 - val_accuracy: 0.6069 - lr: 3.2359e-08\n",
            "Epoch 53/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2021 - accuracy: 0.6069 - val_loss: 0.2020 - val_accuracy: 0.6069 - lr: 3.3113e-08\n",
            "Epoch 54/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2020 - accuracy: 0.6069 - val_loss: 0.2019 - val_accuracy: 0.6069 - lr: 3.3884e-08\n",
            "Epoch 55/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2018 - accuracy: 0.6069 - val_loss: 0.2018 - val_accuracy: 0.6069 - lr: 3.4674e-08\n",
            "Epoch 56/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2017 - accuracy: 0.6069 - val_loss: 0.2016 - val_accuracy: 0.6069 - lr: 3.5481e-08\n",
            "Epoch 57/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2015 - accuracy: 0.6069 - val_loss: 0.2015 - val_accuracy: 0.6069 - lr: 3.6308e-08\n",
            "Epoch 58/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2014 - accuracy: 0.6069 - val_loss: 0.2013 - val_accuracy: 0.6069 - lr: 3.7154e-08\n",
            "Epoch 59/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2012 - accuracy: 0.6069 - val_loss: 0.2012 - val_accuracy: 0.6069 - lr: 3.8019e-08\n",
            "Epoch 60/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.2011 - accuracy: 0.6069 - val_loss: 0.2010 - val_accuracy: 0.6069 - lr: 3.8905e-08\n",
            "Epoch 61/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2009 - accuracy: 0.6069 - val_loss: 0.2009 - val_accuracy: 0.6069 - lr: 3.9811e-08\n",
            "Epoch 62/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2008 - accuracy: 0.6069 - val_loss: 0.2007 - val_accuracy: 0.6069 - lr: 4.0738e-08\n",
            "Epoch 63/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2006 - accuracy: 0.6069 - val_loss: 0.2005 - val_accuracy: 0.6069 - lr: 4.1687e-08\n",
            "Epoch 64/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2004 - accuracy: 0.6069 - val_loss: 0.2004 - val_accuracy: 0.6069 - lr: 4.2658e-08\n",
            "Epoch 65/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2002 - accuracy: 0.6069 - val_loss: 0.2002 - val_accuracy: 0.6069 - lr: 4.3652e-08\n",
            "Epoch 66/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.2001 - accuracy: 0.6069 - val_loss: 0.2000 - val_accuracy: 0.6069 - lr: 4.4668e-08\n",
            "Epoch 67/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1999 - accuracy: 0.6069 - val_loss: 0.1998 - val_accuracy: 0.6069 - lr: 4.5709e-08\n",
            "Epoch 68/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1997 - accuracy: 0.6069 - val_loss: 0.1997 - val_accuracy: 0.6069 - lr: 4.6774e-08\n",
            "Epoch 69/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1995 - accuracy: 0.6069 - val_loss: 0.1995 - val_accuracy: 0.6069 - lr: 4.7863e-08\n",
            "Epoch 70/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1993 - accuracy: 0.6069 - val_loss: 0.1993 - val_accuracy: 0.6069 - lr: 4.8978e-08\n",
            "Epoch 71/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1991 - accuracy: 0.6069 - val_loss: 0.1991 - val_accuracy: 0.6069 - lr: 5.0119e-08\n",
            "Epoch 72/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1989 - accuracy: 0.6069 - val_loss: 0.1989 - val_accuracy: 0.6069 - lr: 5.1286e-08\n",
            "Epoch 73/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1987 - accuracy: 0.6069 - val_loss: 0.1987 - val_accuracy: 0.6069 - lr: 5.2481e-08\n",
            "Epoch 74/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1985 - accuracy: 0.6069 - val_loss: 0.1985 - val_accuracy: 0.6069 - lr: 5.3703e-08\n",
            "Epoch 75/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1983 - accuracy: 0.6069 - val_loss: 0.1982 - val_accuracy: 0.6069 - lr: 5.4954e-08\n",
            "Epoch 76/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1981 - accuracy: 0.6069 - val_loss: 0.1980 - val_accuracy: 0.6069 - lr: 5.6234e-08\n",
            "Epoch 77/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1978 - accuracy: 0.6069 - val_loss: 0.1978 - val_accuracy: 0.6069 - lr: 5.7544e-08\n",
            "Epoch 78/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1976 - accuracy: 0.6069 - val_loss: 0.1976 - val_accuracy: 0.6069 - lr: 5.8884e-08\n",
            "Epoch 79/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1974 - accuracy: 0.6069 - val_loss: 0.1973 - val_accuracy: 0.6069 - lr: 6.0256e-08\n",
            "Epoch 80/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1971 - accuracy: 0.6069 - val_loss: 0.1971 - val_accuracy: 0.6069 - lr: 6.1659e-08\n",
            "Epoch 81/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1969 - accuracy: 0.6069 - val_loss: 0.1969 - val_accuracy: 0.6069 - lr: 6.3096e-08\n",
            "Epoch 82/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1966 - accuracy: 0.6069 - val_loss: 0.1966 - val_accuracy: 0.6069 - lr: 6.4565e-08\n",
            "Epoch 83/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1964 - accuracy: 0.6069 - val_loss: 0.1964 - val_accuracy: 0.6069 - lr: 6.6069e-08\n",
            "Epoch 84/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1961 - accuracy: 0.6069 - val_loss: 0.1961 - val_accuracy: 0.6069 - lr: 6.7608e-08\n",
            "Epoch 85/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1959 - accuracy: 0.6069 - val_loss: 0.1959 - val_accuracy: 0.6069 - lr: 6.9183e-08\n",
            "Epoch 86/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1956 - accuracy: 0.6069 - val_loss: 0.1956 - val_accuracy: 0.6069 - lr: 7.0795e-08\n",
            "Epoch 87/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1953 - accuracy: 0.6069 - val_loss: 0.1953 - val_accuracy: 0.6069 - lr: 7.2444e-08\n",
            "Epoch 88/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1950 - accuracy: 0.6069 - val_loss: 0.1950 - val_accuracy: 0.6069 - lr: 7.4131e-08\n",
            "Epoch 89/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1948 - accuracy: 0.6069 - val_loss: 0.1948 - val_accuracy: 0.6069 - lr: 7.5858e-08\n",
            "Epoch 90/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.1945 - accuracy: 0.6069 - val_loss: 0.1945 - val_accuracy: 0.6069 - lr: 7.7625e-08\n",
            "Epoch 91/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.1942 - accuracy: 0.6069 - val_loss: 0.1942 - val_accuracy: 0.6069 - lr: 7.9433e-08\n",
            "Epoch 92/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1939 - accuracy: 0.6069 - val_loss: 0.1939 - val_accuracy: 0.6069 - lr: 8.1283e-08\n",
            "Epoch 93/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1936 - accuracy: 0.6069 - val_loss: 0.1936 - val_accuracy: 0.6069 - lr: 8.3176e-08\n",
            "Epoch 94/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1933 - accuracy: 0.6069 - val_loss: 0.1933 - val_accuracy: 0.6069 - lr: 8.5114e-08\n",
            "Epoch 95/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1930 - accuracy: 0.6069 - val_loss: 0.1930 - val_accuracy: 0.6069 - lr: 8.7096e-08\n",
            "Epoch 96/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1926 - accuracy: 0.6069 - val_loss: 0.1927 - val_accuracy: 0.6069 - lr: 8.9125e-08\n",
            "Epoch 97/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.1923 - accuracy: 0.6069 - val_loss: 0.1923 - val_accuracy: 0.6069 - lr: 9.1201e-08\n",
            "Epoch 98/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.6069 - val_loss: 0.1920 - val_accuracy: 0.6069 - lr: 9.3325e-08\n",
            "Epoch 99/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.6069 - val_loss: 0.1917 - val_accuracy: 0.6069 - lr: 9.5499e-08\n",
            "Epoch 100/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1913 - accuracy: 0.6069 - val_loss: 0.1913 - val_accuracy: 0.6069 - lr: 9.7724e-08\n",
            "Epoch 101/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1910 - accuracy: 0.6069 - val_loss: 0.1910 - val_accuracy: 0.6069 - lr: 1.0000e-07\n",
            "Epoch 102/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1906 - accuracy: 0.6069 - val_loss: 0.1906 - val_accuracy: 0.6069 - lr: 1.0233e-07\n",
            "Epoch 103/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1902 - accuracy: 0.6069 - val_loss: 0.1903 - val_accuracy: 0.6069 - lr: 1.0471e-07\n",
            "Epoch 104/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1899 - accuracy: 0.6069 - val_loss: 0.1899 - val_accuracy: 0.6069 - lr: 1.0715e-07\n",
            "Epoch 105/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1895 - accuracy: 0.6069 - val_loss: 0.1895 - val_accuracy: 0.6069 - lr: 1.0965e-07\n",
            "Epoch 106/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1891 - accuracy: 0.6069 - val_loss: 0.1892 - val_accuracy: 0.6069 - lr: 1.1220e-07\n",
            "Epoch 107/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1887 - accuracy: 0.6069 - val_loss: 0.1888 - val_accuracy: 0.6069 - lr: 1.1482e-07\n",
            "Epoch 108/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1883 - accuracy: 0.6069 - val_loss: 0.1884 - val_accuracy: 0.6069 - lr: 1.1749e-07\n",
            "Epoch 109/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1879 - accuracy: 0.6069 - val_loss: 0.1880 - val_accuracy: 0.6069 - lr: 1.2023e-07\n",
            "Epoch 110/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1875 - accuracy: 0.6069 - val_loss: 0.1876 - val_accuracy: 0.6069 - lr: 1.2303e-07\n",
            "Epoch 111/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1871 - accuracy: 0.6069 - val_loss: 0.1872 - val_accuracy: 0.6069 - lr: 1.2589e-07\n",
            "Epoch 112/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1867 - accuracy: 0.6069 - val_loss: 0.1868 - val_accuracy: 0.6069 - lr: 1.2882e-07\n",
            "Epoch 113/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1863 - accuracy: 0.6069 - val_loss: 0.1863 - val_accuracy: 0.6069 - lr: 1.3183e-07\n",
            "Epoch 114/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1858 - accuracy: 0.6069 - val_loss: 0.1859 - val_accuracy: 0.6069 - lr: 1.3490e-07\n",
            "Epoch 115/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1854 - accuracy: 0.6069 - val_loss: 0.1855 - val_accuracy: 0.6069 - lr: 1.3804e-07\n",
            "Epoch 116/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1849 - accuracy: 0.6069 - val_loss: 0.1850 - val_accuracy: 0.6069 - lr: 1.4125e-07\n",
            "Epoch 117/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1845 - accuracy: 0.6069 - val_loss: 0.1846 - val_accuracy: 0.6069 - lr: 1.4454e-07\n",
            "Epoch 118/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.1840 - accuracy: 0.6069 - val_loss: 0.1841 - val_accuracy: 0.6069 - lr: 1.4791e-07\n",
            "Epoch 119/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1835 - accuracy: 0.6069 - val_loss: 0.1836 - val_accuracy: 0.6069 - lr: 1.5136e-07\n",
            "Epoch 120/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1830 - accuracy: 0.6069 - val_loss: 0.1832 - val_accuracy: 0.6069 - lr: 1.5488e-07\n",
            "Epoch 121/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1825 - accuracy: 0.6069 - val_loss: 0.1827 - val_accuracy: 0.6069 - lr: 1.5849e-07\n",
            "Epoch 122/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1820 - accuracy: 0.6069 - val_loss: 0.1821 - val_accuracy: 0.6069 - lr: 1.6218e-07\n",
            "Epoch 123/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1815 - accuracy: 0.6069 - val_loss: 0.1816 - val_accuracy: 0.6069 - lr: 1.6596e-07\n",
            "Epoch 124/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1810 - accuracy: 0.6069 - val_loss: 0.1811 - val_accuracy: 0.6069 - lr: 1.6982e-07\n",
            "Epoch 125/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1804 - accuracy: 0.6069 - val_loss: 0.1806 - val_accuracy: 0.6069 - lr: 1.7378e-07\n",
            "Epoch 126/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1799 - accuracy: 0.6069 - val_loss: 0.1800 - val_accuracy: 0.6069 - lr: 1.7783e-07\n",
            "Epoch 127/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1793 - accuracy: 0.6069 - val_loss: 0.1794 - val_accuracy: 0.6069 - lr: 1.8197e-07\n",
            "Epoch 128/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.6069 - val_loss: 0.1789 - val_accuracy: 0.6069 - lr: 1.8621e-07\n",
            "Epoch 129/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.6069 - val_loss: 0.1783 - val_accuracy: 0.6069 - lr: 1.9055e-07\n",
            "Epoch 130/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1775 - accuracy: 0.6069 - val_loss: 0.1777 - val_accuracy: 0.6069 - lr: 1.9498e-07\n",
            "Epoch 131/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1769 - accuracy: 0.6069 - val_loss: 0.1770 - val_accuracy: 0.6069 - lr: 1.9953e-07\n",
            "Epoch 132/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1762 - accuracy: 0.6069 - val_loss: 0.1764 - val_accuracy: 0.6069 - lr: 2.0417e-07\n",
            "Epoch 133/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.6069 - val_loss: 0.1757 - val_accuracy: 0.6069 - lr: 2.0893e-07\n",
            "Epoch 134/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1749 - accuracy: 0.6069 - val_loss: 0.1751 - val_accuracy: 0.6069 - lr: 2.1380e-07\n",
            "Epoch 135/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1742 - accuracy: 0.6069 - val_loss: 0.1744 - val_accuracy: 0.6069 - lr: 2.1878e-07\n",
            "Epoch 136/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 0.6069 - val_loss: 0.1737 - val_accuracy: 0.6069 - lr: 2.2387e-07\n",
            "Epoch 137/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1727 - accuracy: 0.6069 - val_loss: 0.1729 - val_accuracy: 0.6069 - lr: 2.2909e-07\n",
            "Epoch 138/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1720 - accuracy: 0.6069 - val_loss: 0.1722 - val_accuracy: 0.6069 - lr: 2.3442e-07\n",
            "Epoch 139/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1712 - accuracy: 0.6069 - val_loss: 0.1715 - val_accuracy: 0.6069 - lr: 2.3988e-07\n",
            "Epoch 140/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.6069 - val_loss: 0.1707 - val_accuracy: 0.6069 - lr: 2.4547e-07\n",
            "Epoch 141/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1697 - accuracy: 0.6069 - val_loss: 0.1700 - val_accuracy: 0.6069 - lr: 2.5119e-07\n",
            "Epoch 142/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1689 - accuracy: 0.6069 - val_loss: 0.1692 - val_accuracy: 0.6069 - lr: 2.5704e-07\n",
            "Epoch 143/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1682 - accuracy: 0.6069 - val_loss: 0.1684 - val_accuracy: 0.6069 - lr: 2.6303e-07\n",
            "Epoch 144/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1674 - accuracy: 0.6069 - val_loss: 0.1677 - val_accuracy: 0.6069 - lr: 2.6915e-07\n",
            "Epoch 145/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1666 - accuracy: 0.6069 - val_loss: 0.1669 - val_accuracy: 0.6069 - lr: 2.7542e-07\n",
            "Epoch 146/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.1658 - accuracy: 0.6069 - val_loss: 0.1661 - val_accuracy: 0.6069 - lr: 2.8184e-07\n",
            "Epoch 147/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.6069 - val_loss: 0.1653 - val_accuracy: 0.6069 - lr: 2.8840e-07\n",
            "Epoch 148/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1642 - accuracy: 0.6069 - val_loss: 0.1646 - val_accuracy: 0.6069 - lr: 2.9512e-07\n",
            "Epoch 149/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1634 - accuracy: 0.6069 - val_loss: 0.1638 - val_accuracy: 0.6069 - lr: 3.0200e-07\n",
            "Epoch 150/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1626 - accuracy: 0.6069 - val_loss: 0.1630 - val_accuracy: 0.6069 - lr: 3.0903e-07\n",
            "Epoch 151/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1618 - accuracy: 0.6069 - val_loss: 0.1622 - val_accuracy: 0.6069 - lr: 3.1623e-07\n",
            "Epoch 152/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1610 - accuracy: 0.6069 - val_loss: 0.1614 - val_accuracy: 0.6069 - lr: 3.2359e-07\n",
            "Epoch 153/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1602 - accuracy: 0.6069 - val_loss: 0.1607 - val_accuracy: 0.6069 - lr: 3.3113e-07\n",
            "Epoch 154/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1594 - accuracy: 0.6069 - val_loss: 0.1599 - val_accuracy: 0.6069 - lr: 3.3884e-07\n",
            "Epoch 155/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.6069 - val_loss: 0.1591 - val_accuracy: 0.6069 - lr: 3.4674e-07\n",
            "Epoch 156/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1578 - accuracy: 0.6069 - val_loss: 0.1582 - val_accuracy: 0.6069 - lr: 3.5481e-07\n",
            "Epoch 157/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.6069 - val_loss: 0.1574 - val_accuracy: 0.6069 - lr: 3.6308e-07\n",
            "Epoch 158/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1561 - accuracy: 0.6069 - val_loss: 0.1566 - val_accuracy: 0.6069 - lr: 3.7154e-07\n",
            "Epoch 159/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1552 - accuracy: 0.6069 - val_loss: 0.1558 - val_accuracy: 0.6069 - lr: 3.8019e-07\n",
            "Epoch 160/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.6069 - val_loss: 0.1549 - val_accuracy: 0.6069 - lr: 3.8905e-07\n",
            "Epoch 161/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1535 - accuracy: 0.6069 - val_loss: 0.1541 - val_accuracy: 0.6069 - lr: 3.9811e-07\n",
            "Epoch 162/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1526 - accuracy: 0.6069 - val_loss: 0.1532 - val_accuracy: 0.6069 - lr: 4.0738e-07\n",
            "Epoch 163/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1517 - accuracy: 0.6069 - val_loss: 0.1523 - val_accuracy: 0.6069 - lr: 4.1687e-07\n",
            "Epoch 164/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1508 - accuracy: 0.6069 - val_loss: 0.1515 - val_accuracy: 0.6069 - lr: 4.2658e-07\n",
            "Epoch 165/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1500 - accuracy: 0.6069 - val_loss: 0.1506 - val_accuracy: 0.6069 - lr: 4.3652e-07\n",
            "Epoch 166/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1491 - accuracy: 0.6069 - val_loss: 0.1497 - val_accuracy: 0.6069 - lr: 4.4668e-07\n",
            "Epoch 167/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.6069 - val_loss: 0.1489 - val_accuracy: 0.6069 - lr: 4.5709e-07\n",
            "Epoch 168/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.1473 - accuracy: 0.6069 - val_loss: 0.1480 - val_accuracy: 0.6069 - lr: 4.6774e-07\n",
            "Epoch 169/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.1464 - accuracy: 0.6069 - val_loss: 0.1471 - val_accuracy: 0.6069 - lr: 4.7863e-07\n",
            "Epoch 170/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.1455 - accuracy: 0.6069 - val_loss: 0.1462 - val_accuracy: 0.6069 - lr: 4.8978e-07\n",
            "Epoch 171/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.6069 - val_loss: 0.1454 - val_accuracy: 0.6069 - lr: 5.0119e-07\n",
            "Epoch 172/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1437 - accuracy: 0.6069 - val_loss: 0.1445 - val_accuracy: 0.6069 - lr: 5.1286e-07\n",
            "Epoch 173/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.6069 - val_loss: 0.1436 - val_accuracy: 0.6069 - lr: 5.2481e-07\n",
            "Epoch 174/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1418 - accuracy: 0.6069 - val_loss: 0.1427 - val_accuracy: 0.6069 - lr: 5.3703e-07\n",
            "Epoch 175/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1409 - accuracy: 0.6069 - val_loss: 0.1418 - val_accuracy: 0.6069 - lr: 5.4954e-07\n",
            "Epoch 176/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1400 - accuracy: 0.6069 - val_loss: 0.1409 - val_accuracy: 0.6069 - lr: 5.6234e-07\n",
            "Epoch 177/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1391 - accuracy: 0.6069 - val_loss: 0.1400 - val_accuracy: 0.6069 - lr: 5.7544e-07\n",
            "Epoch 178/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.1382 - accuracy: 0.6069 - val_loss: 0.1391 - val_accuracy: 0.6069 - lr: 5.8884e-07\n",
            "Epoch 179/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1371 - accuracy: 0.6069 - val_loss: 0.1380 - val_accuracy: 0.6069 - lr: 6.0256e-07\n",
            "Epoch 180/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1360 - accuracy: 0.6069 - val_loss: 0.1368 - val_accuracy: 0.6069 - lr: 6.1660e-07\n",
            "Epoch 181/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1348 - accuracy: 0.6069 - val_loss: 0.1357 - val_accuracy: 0.6069 - lr: 6.3096e-07\n",
            "Epoch 182/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.6069 - val_loss: 0.1345 - val_accuracy: 0.6069 - lr: 6.4565e-07\n",
            "Epoch 183/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.6069 - val_loss: 0.1334 - val_accuracy: 0.6069 - lr: 6.6069e-07\n",
            "Epoch 184/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.6069 - val_loss: 0.1322 - val_accuracy: 0.6069 - lr: 6.7608e-07\n",
            "Epoch 185/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.6069 - val_loss: 0.1308 - val_accuracy: 0.6069 - lr: 6.9183e-07\n",
            "Epoch 186/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.6069 - val_loss: 0.1291 - val_accuracy: 0.6069 - lr: 7.0795e-07\n",
            "Epoch 187/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1267 - accuracy: 0.6069 - val_loss: 0.1274 - val_accuracy: 0.6069 - lr: 7.2444e-07\n",
            "Epoch 188/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 0.6069 - val_loss: 0.1258 - val_accuracy: 0.6069 - lr: 7.4131e-07\n",
            "Epoch 189/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.6069 - val_loss: 0.1243 - val_accuracy: 0.6069 - lr: 7.5858e-07\n",
            "Epoch 190/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.6069 - val_loss: 0.1229 - val_accuracy: 0.6069 - lr: 7.7625e-07\n",
            "Epoch 191/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1205 - accuracy: 0.6069 - val_loss: 0.1215 - val_accuracy: 0.6069 - lr: 7.9433e-07\n",
            "Epoch 192/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1191 - accuracy: 0.6069 - val_loss: 0.1201 - val_accuracy: 0.6069 - lr: 8.1283e-07\n",
            "Epoch 193/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1178 - accuracy: 0.6069 - val_loss: 0.1189 - val_accuracy: 0.6069 - lr: 8.3176e-07\n",
            "Epoch 194/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.6069 - val_loss: 0.1176 - val_accuracy: 0.6069 - lr: 8.5114e-07\n",
            "Epoch 195/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1153 - accuracy: 0.6069 - val_loss: 0.1164 - val_accuracy: 0.6069 - lr: 8.7096e-07\n",
            "Epoch 196/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.6069 - val_loss: 0.1150 - val_accuracy: 0.6069 - lr: 8.9125e-07\n",
            "Epoch 197/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.6069 - val_loss: 0.1137 - val_accuracy: 0.6069 - lr: 9.1201e-07\n",
            "Epoch 198/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.1112 - accuracy: 0.6069 - val_loss: 0.1123 - val_accuracy: 0.6069 - lr: 9.3325e-07\n",
            "Epoch 199/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1098 - accuracy: 0.6069 - val_loss: 0.1109 - val_accuracy: 0.6069 - lr: 9.5499e-07\n",
            "Epoch 200/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1084 - accuracy: 0.6069 - val_loss: 0.1095 - val_accuracy: 0.6069 - lr: 9.7724e-07\n",
            "Epoch 201/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.1070 - accuracy: 0.6069 - val_loss: 0.1081 - val_accuracy: 0.6069 - lr: 1.0000e-06\n",
            "Epoch 202/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1055 - accuracy: 0.6069 - val_loss: 0.1066 - val_accuracy: 0.6069 - lr: 1.0233e-06\n",
            "Epoch 203/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.6069 - val_loss: 0.1051 - val_accuracy: 0.6069 - lr: 1.0471e-06\n",
            "Epoch 204/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.1025 - accuracy: 0.6069 - val_loss: 0.1034 - val_accuracy: 0.6069 - lr: 1.0715e-06\n",
            "Epoch 205/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.1008 - accuracy: 0.6077 - val_loss: 0.1017 - val_accuracy: 0.6097 - lr: 1.0965e-06\n",
            "Epoch 206/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.6131 - val_loss: 0.0997 - val_accuracy: 0.6217 - lr: 1.1220e-06\n",
            "Epoch 207/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0968 - accuracy: 0.6283 - val_loss: 0.0975 - val_accuracy: 0.6484 - lr: 1.1482e-06\n",
            "Epoch 208/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0945 - accuracy: 0.6569 - val_loss: 0.0952 - val_accuracy: 0.6747 - lr: 1.1749e-06\n",
            "Epoch 209/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0923 - accuracy: 0.6896 - val_loss: 0.0931 - val_accuracy: 0.7069 - lr: 1.2023e-06\n",
            "Epoch 210/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0902 - accuracy: 0.7190 - val_loss: 0.0909 - val_accuracy: 0.7372 - lr: 1.2303e-06\n",
            "Epoch 211/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0881 - accuracy: 0.7503 - val_loss: 0.0888 - val_accuracy: 0.7661 - lr: 1.2589e-06\n",
            "Epoch 212/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0860 - accuracy: 0.7843 - val_loss: 0.0868 - val_accuracy: 0.7928 - lr: 1.2882e-06\n",
            "Epoch 213/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0840 - accuracy: 0.8035 - val_loss: 0.0849 - val_accuracy: 0.8079 - lr: 1.3183e-06\n",
            "Epoch 214/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0821 - accuracy: 0.8180 - val_loss: 0.0829 - val_accuracy: 0.8152 - lr: 1.3490e-06\n",
            "Epoch 215/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.8254 - val_loss: 0.0809 - val_accuracy: 0.8206 - lr: 1.3804e-06\n",
            "Epoch 216/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0780 - accuracy: 0.8306 - val_loss: 0.0786 - val_accuracy: 0.8264 - lr: 1.4125e-06\n",
            "Epoch 217/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.8326 - val_loss: 0.0759 - val_accuracy: 0.8285 - lr: 1.4454e-06\n",
            "Epoch 218/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0727 - accuracy: 0.8352 - val_loss: 0.0732 - val_accuracy: 0.8307 - lr: 1.4791e-06\n",
            "Epoch 219/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.8368 - val_loss: 0.0706 - val_accuracy: 0.8318 - lr: 1.5136e-06\n",
            "Epoch 220/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.8386 - val_loss: 0.0682 - val_accuracy: 0.8343 - lr: 1.5488e-06\n",
            "Epoch 221/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.8398 - val_loss: 0.0659 - val_accuracy: 0.8354 - lr: 1.5849e-06\n",
            "Epoch 222/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.8410 - val_loss: 0.0636 - val_accuracy: 0.8383 - lr: 1.6218e-06\n",
            "Epoch 223/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0607 - accuracy: 0.8498 - val_loss: 0.0614 - val_accuracy: 0.8491 - lr: 1.6596e-06\n",
            "Epoch 224/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0584 - accuracy: 0.8571 - val_loss: 0.0592 - val_accuracy: 0.8549 - lr: 1.6982e-06\n",
            "Epoch 225/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0562 - accuracy: 0.8627 - val_loss: 0.0570 - val_accuracy: 0.8585 - lr: 1.7378e-06\n",
            "Epoch 226/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0541 - accuracy: 0.8682 - val_loss: 0.0549 - val_accuracy: 0.8635 - lr: 1.7783e-06\n",
            "Epoch 227/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0520 - accuracy: 0.8729 - val_loss: 0.0528 - val_accuracy: 0.8690 - lr: 1.8197e-06\n",
            "Epoch 228/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.8769 - val_loss: 0.0507 - val_accuracy: 0.8733 - lr: 1.8621e-06\n",
            "Epoch 229/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.8807 - val_loss: 0.0487 - val_accuracy: 0.8758 - lr: 1.9055e-06\n",
            "Epoch 230/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.8859 - val_loss: 0.0467 - val_accuracy: 0.8791 - lr: 1.9498e-06\n",
            "Epoch 231/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.8894 - val_loss: 0.0447 - val_accuracy: 0.8819 - lr: 1.9953e-06\n",
            "Epoch 232/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0419 - accuracy: 0.8927 - val_loss: 0.0428 - val_accuracy: 0.8841 - lr: 2.0417e-06\n",
            "Epoch 233/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.8955 - val_loss: 0.0409 - val_accuracy: 0.8881 - lr: 2.0893e-06\n",
            "Epoch 234/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.8982 - val_loss: 0.0391 - val_accuracy: 0.8906 - lr: 2.1380e-06\n",
            "Epoch 235/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0364 - accuracy: 0.9004 - val_loss: 0.0374 - val_accuracy: 0.8924 - lr: 2.1878e-06\n",
            "Epoch 236/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0347 - accuracy: 0.9022 - val_loss: 0.0357 - val_accuracy: 0.8939 - lr: 2.2387e-06\n",
            "Epoch 237/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0331 - accuracy: 0.9044 - val_loss: 0.0341 - val_accuracy: 0.8971 - lr: 2.2909e-06\n",
            "Epoch 238/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9074 - val_loss: 0.0325 - val_accuracy: 0.8996 - lr: 2.3442e-06\n",
            "Epoch 239/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0300 - accuracy: 0.9093 - val_loss: 0.0310 - val_accuracy: 0.9011 - lr: 2.3988e-06\n",
            "Epoch 240/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9109 - val_loss: 0.0296 - val_accuracy: 0.9043 - lr: 2.4547e-06\n",
            "Epoch 241/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.9127 - val_loss: 0.0283 - val_accuracy: 0.9065 - lr: 2.5119e-06\n",
            "Epoch 242/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9147 - val_loss: 0.0271 - val_accuracy: 0.9083 - lr: 2.5704e-06\n",
            "Epoch 243/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9171 - val_loss: 0.0260 - val_accuracy: 0.9116 - lr: 2.6303e-06\n",
            "Epoch 244/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9198 - val_loss: 0.0250 - val_accuracy: 0.9155 - lr: 2.6915e-06\n",
            "Epoch 245/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9226 - val_loss: 0.0240 - val_accuracy: 0.9177 - lr: 2.7542e-06\n",
            "Epoch 246/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0219 - accuracy: 0.9252 - val_loss: 0.0230 - val_accuracy: 0.9199 - lr: 2.8184e-06\n",
            "Epoch 247/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9272 - val_loss: 0.0221 - val_accuracy: 0.9227 - lr: 2.8840e-06\n",
            "Epoch 248/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9299 - val_loss: 0.0213 - val_accuracy: 0.9264 - lr: 2.9512e-06\n",
            "Epoch 249/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0194 - accuracy: 0.9326 - val_loss: 0.0204 - val_accuracy: 0.9296 - lr: 3.0200e-06\n",
            "Epoch 250/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0187 - accuracy: 0.9340 - val_loss: 0.0197 - val_accuracy: 0.9321 - lr: 3.0903e-06\n",
            "Epoch 251/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0179 - accuracy: 0.9364 - val_loss: 0.0189 - val_accuracy: 0.9332 - lr: 3.1623e-06\n",
            "Epoch 252/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0172 - accuracy: 0.9392 - val_loss: 0.0181 - val_accuracy: 0.9361 - lr: 3.2359e-06\n",
            "Epoch 253/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9421 - val_loss: 0.0174 - val_accuracy: 0.9390 - lr: 3.3113e-06\n",
            "Epoch 254/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9450 - val_loss: 0.0167 - val_accuracy: 0.9397 - lr: 3.3884e-06\n",
            "Epoch 255/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9477 - val_loss: 0.0160 - val_accuracy: 0.9444 - lr: 3.4674e-06\n",
            "Epoch 256/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9498 - val_loss: 0.0154 - val_accuracy: 0.9466 - lr: 3.5481e-06\n",
            "Epoch 257/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9519 - val_loss: 0.0148 - val_accuracy: 0.9491 - lr: 3.6308e-06\n",
            "Epoch 258/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 0.9541 - val_loss: 0.0142 - val_accuracy: 0.9531 - lr: 3.7154e-06\n",
            "Epoch 259/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9559 - val_loss: 0.0136 - val_accuracy: 0.9560 - lr: 3.8019e-06\n",
            "Epoch 260/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9584 - val_loss: 0.0130 - val_accuracy: 0.9581 - lr: 3.8905e-06\n",
            "Epoch 261/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9615 - val_loss: 0.0125 - val_accuracy: 0.9603 - lr: 3.9811e-06\n",
            "Epoch 262/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.9636 - val_loss: 0.0119 - val_accuracy: 0.9661 - lr: 4.0738e-06\n",
            "Epoch 263/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9671 - val_loss: 0.0114 - val_accuracy: 0.9675 - lr: 4.1687e-06\n",
            "Epoch 264/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9701 - val_loss: 0.0109 - val_accuracy: 0.9708 - lr: 4.2658e-06\n",
            "Epoch 265/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.9731 - val_loss: 0.0104 - val_accuracy: 0.9736 - lr: 4.3652e-06\n",
            "Epoch 266/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9767 - val_loss: 0.0099 - val_accuracy: 0.9776 - lr: 4.4668e-06\n",
            "Epoch 267/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9819 - val_loss: 0.0094 - val_accuracy: 0.9845 - lr: 4.5709e-06\n",
            "Epoch 268/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.9867 - val_loss: 0.0089 - val_accuracy: 0.9881 - lr: 4.6774e-06\n",
            "Epoch 269/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9917 - val_loss: 0.0084 - val_accuracy: 0.9924 - lr: 4.7863e-06\n",
            "Epoch 270/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.0080 - val_accuracy: 1.0000 - lr: 4.8978e-06\n",
            "Epoch 271/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.9997 - val_loss: 0.0075 - val_accuracy: 1.0000 - lr: 5.0119e-06\n",
            "Epoch 272/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.9997 - val_loss: 0.0071 - val_accuracy: 1.0000 - lr: 5.1286e-06\n",
            "Epoch 273/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 0.0067 - val_accuracy: 1.0000 - lr: 5.2481e-06\n",
            "Epoch 274/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9997 - val_loss: 0.0063 - val_accuracy: 1.0000 - lr: 5.3703e-06\n",
            "Epoch 275/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.9997 - val_loss: 0.0059 - val_accuracy: 1.0000 - lr: 5.4954e-06\n",
            "Epoch 276/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.0055 - val_accuracy: 1.0000 - lr: 5.6234e-06\n",
            "Epoch 277/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9997 - val_loss: 0.0051 - val_accuracy: 1.0000 - lr: 5.7544e-06\n",
            "Epoch 278/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 5.8884e-06\n",
            "Epoch 279/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.0044 - val_accuracy: 1.0000 - lr: 6.0256e-06\n",
            "Epoch 280/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 1.0000 - lr: 6.1659e-06\n",
            "Epoch 281/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.0038 - val_accuracy: 1.0000 - lr: 6.3096e-06\n",
            "Epoch 282/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0035 - val_accuracy: 1.0000 - lr: 6.4565e-06\n",
            "Epoch 283/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0032 - val_accuracy: 1.0000 - lr: 6.6069e-06\n",
            "Epoch 284/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0029 - val_accuracy: 1.0000 - lr: 6.7608e-06\n",
            "Epoch 285/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0026 - val_accuracy: 1.0000 - lr: 6.9183e-06\n",
            "Epoch 286/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0024 - val_accuracy: 1.0000 - lr: 7.0795e-06\n",
            "Epoch 287/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0022 - val_accuracy: 1.0000 - lr: 7.2444e-06\n",
            "Epoch 288/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0020 - val_accuracy: 1.0000 - lr: 7.4131e-06\n",
            "Epoch 289/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0018 - val_accuracy: 1.0000 - lr: 7.5858e-06\n",
            "Epoch 290/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0016 - val_accuracy: 1.0000 - lr: 7.7625e-06\n",
            "Epoch 291/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0015 - val_accuracy: 1.0000 - lr: 7.9433e-06\n",
            "Epoch 292/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 8.1283e-06\n",
            "Epoch 293/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0012 - val_accuracy: 1.0000 - lr: 8.3176e-06\n",
            "Epoch 294/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 8.5114e-06\n",
            "Epoch 295/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0010 - val_accuracy: 1.0000 - lr: 8.7096e-06\n",
            "Epoch 296/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 9.6047e-04 - val_accuracy: 1.0000 - lr: 8.9125e-06\n",
            "Epoch 297/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.3844e-04 - accuracy: 0.9996 - val_loss: 8.7314e-04 - val_accuracy: 1.0000 - lr: 9.1201e-06\n",
            "Epoch 298/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.7916e-04 - accuracy: 0.9997 - val_loss: 8.1673e-04 - val_accuracy: 1.0000 - lr: 9.3325e-06\n",
            "Epoch 299/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 8.2306e-04 - accuracy: 0.9997 - val_loss: 7.5667e-04 - val_accuracy: 1.0000 - lr: 9.5499e-06\n",
            "Epoch 300/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.7952e-04 - accuracy: 0.9997 - val_loss: 7.1596e-04 - val_accuracy: 1.0000 - lr: 9.7724e-06\n",
            "Epoch 301/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.4471e-04 - accuracy: 0.9997 - val_loss: 6.9373e-04 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 302/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.1312e-04 - accuracy: 0.9997 - val_loss: 6.5717e-04 - val_accuracy: 1.0000 - lr: 1.0233e-05\n",
            "Epoch 303/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.8578e-04 - accuracy: 0.9997 - val_loss: 6.3025e-04 - val_accuracy: 1.0000 - lr: 1.0471e-05\n",
            "Epoch 304/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.6639e-04 - accuracy: 0.9997 - val_loss: 6.0312e-04 - val_accuracy: 1.0000 - lr: 1.0715e-05\n",
            "Epoch 305/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.4429e-04 - accuracy: 0.9997 - val_loss: 5.8046e-04 - val_accuracy: 1.0000 - lr: 1.0965e-05\n",
            "Epoch 306/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.2922e-04 - accuracy: 0.9997 - val_loss: 5.6539e-04 - val_accuracy: 1.0000 - lr: 1.1220e-05\n",
            "Epoch 307/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.1312e-04 - accuracy: 0.9997 - val_loss: 5.5460e-04 - val_accuracy: 1.0000 - lr: 1.1482e-05\n",
            "Epoch 308/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.9957e-04 - accuracy: 0.9997 - val_loss: 5.3932e-04 - val_accuracy: 1.0000 - lr: 1.1749e-05\n",
            "Epoch 309/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.8884e-04 - accuracy: 0.9997 - val_loss: 5.3271e-04 - val_accuracy: 1.0000 - lr: 1.2023e-05\n",
            "Epoch 310/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.7824e-04 - accuracy: 0.9997 - val_loss: 5.1075e-04 - val_accuracy: 1.0000 - lr: 1.2303e-05\n",
            "Epoch 311/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.6372e-04 - accuracy: 0.9997 - val_loss: 4.9767e-04 - val_accuracy: 1.0000 - lr: 1.2589e-05\n",
            "Epoch 312/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 5.5202e-04 - accuracy: 0.9997 - val_loss: 4.9236e-04 - val_accuracy: 1.0000 - lr: 1.2882e-05\n",
            "Epoch 313/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 5.4301e-04 - accuracy: 0.9997 - val_loss: 4.7624e-04 - val_accuracy: 1.0000 - lr: 1.3183e-05\n",
            "Epoch 314/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.3063e-04 - accuracy: 0.9997 - val_loss: 4.6656e-04 - val_accuracy: 1.0000 - lr: 1.3490e-05\n",
            "Epoch 315/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 5.1970e-04 - accuracy: 0.9997 - val_loss: 4.6963e-04 - val_accuracy: 1.0000 - lr: 1.3804e-05\n",
            "Epoch 316/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 5.1213e-04 - accuracy: 0.9997 - val_loss: 4.4670e-04 - val_accuracy: 1.0000 - lr: 1.4125e-05\n",
            "Epoch 317/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.9953e-04 - accuracy: 0.9997 - val_loss: 4.3953e-04 - val_accuracy: 1.0000 - lr: 1.4454e-05\n",
            "Epoch 318/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.9344e-04 - accuracy: 0.9997 - val_loss: 4.1759e-04 - val_accuracy: 1.0000 - lr: 1.4791e-05\n",
            "Epoch 319/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.8011e-04 - accuracy: 0.9997 - val_loss: 4.1100e-04 - val_accuracy: 1.0000 - lr: 1.5136e-05\n",
            "Epoch 320/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.7189e-04 - accuracy: 0.9997 - val_loss: 3.9582e-04 - val_accuracy: 1.0000 - lr: 1.5488e-05\n",
            "Epoch 321/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.6088e-04 - accuracy: 0.9997 - val_loss: 3.8619e-04 - val_accuracy: 1.0000 - lr: 1.5849e-05\n",
            "Epoch 322/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.5373e-04 - accuracy: 0.9997 - val_loss: 3.9461e-04 - val_accuracy: 1.0000 - lr: 1.6218e-05\n",
            "Epoch 323/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.4847e-04 - accuracy: 0.9997 - val_loss: 3.8199e-04 - val_accuracy: 1.0000 - lr: 1.6596e-05\n",
            "Epoch 324/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.3676e-04 - accuracy: 0.9997 - val_loss: 3.6115e-04 - val_accuracy: 1.0000 - lr: 1.6982e-05\n",
            "Epoch 325/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.2918e-04 - accuracy: 0.9997 - val_loss: 3.5528e-04 - val_accuracy: 1.0000 - lr: 1.7378e-05\n",
            "Epoch 326/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.2135e-04 - accuracy: 0.9997 - val_loss: 3.6334e-04 - val_accuracy: 1.0000 - lr: 1.7783e-05\n",
            "Epoch 327/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 4.1462e-04 - accuracy: 0.9997 - val_loss: 3.3781e-04 - val_accuracy: 1.0000 - lr: 1.8197e-05\n",
            "Epoch 328/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.0942e-04 - accuracy: 0.9997 - val_loss: 3.3464e-04 - val_accuracy: 1.0000 - lr: 1.8621e-05\n",
            "Epoch 329/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.0194e-04 - accuracy: 0.9997 - val_loss: 3.8119e-04 - val_accuracy: 1.0000 - lr: 1.9055e-05\n",
            "Epoch 330/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.0093e-04 - accuracy: 0.9997 - val_loss: 3.2023e-04 - val_accuracy: 1.0000 - lr: 1.9498e-05\n",
            "Epoch 331/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.8691e-04 - accuracy: 0.9997 - val_loss: 3.1544e-04 - val_accuracy: 1.0000 - lr: 1.9953e-05\n",
            "Epoch 332/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 3.8416e-04 - accuracy: 0.9997 - val_loss: 3.0625e-04 - val_accuracy: 1.0000 - lr: 2.0417e-05\n",
            "Epoch 333/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.7924e-04 - accuracy: 0.9997 - val_loss: 3.0231e-04 - val_accuracy: 1.0000 - lr: 2.0893e-05\n",
            "Epoch 334/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.7058e-04 - accuracy: 0.9997 - val_loss: 3.0101e-04 - val_accuracy: 1.0000 - lr: 2.1380e-05\n",
            "Epoch 335/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.6377e-04 - accuracy: 0.9997 - val_loss: 2.8875e-04 - val_accuracy: 1.0000 - lr: 2.1878e-05\n",
            "Epoch 336/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.6038e-04 - accuracy: 0.9997 - val_loss: 2.8323e-04 - val_accuracy: 1.0000 - lr: 2.2387e-05\n",
            "Epoch 337/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.5695e-04 - accuracy: 0.9997 - val_loss: 2.8117e-04 - val_accuracy: 1.0000 - lr: 2.2909e-05\n",
            "Epoch 338/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.4699e-04 - accuracy: 0.9997 - val_loss: 2.6908e-04 - val_accuracy: 1.0000 - lr: 2.3442e-05\n",
            "Epoch 339/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.4170e-04 - accuracy: 0.9997 - val_loss: 2.6643e-04 - val_accuracy: 1.0000 - lr: 2.3988e-05\n",
            "Epoch 340/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.3958e-04 - accuracy: 0.9997 - val_loss: 2.6357e-04 - val_accuracy: 1.0000 - lr: 2.4547e-05\n",
            "Epoch 341/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 3.3190e-04 - accuracy: 0.9997 - val_loss: 2.6196e-04 - val_accuracy: 1.0000 - lr: 2.5119e-05\n",
            "Epoch 342/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 3.2698e-04 - accuracy: 0.9997 - val_loss: 2.4834e-04 - val_accuracy: 1.0000 - lr: 2.5704e-05\n",
            "Epoch 343/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.2106e-04 - accuracy: 0.9997 - val_loss: 2.6011e-04 - val_accuracy: 1.0000 - lr: 2.6303e-05\n",
            "Epoch 344/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.1560e-04 - accuracy: 0.9997 - val_loss: 2.4343e-04 - val_accuracy: 1.0000 - lr: 2.6915e-05\n",
            "Epoch 345/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.1214e-04 - accuracy: 0.9997 - val_loss: 2.3441e-04 - val_accuracy: 1.0000 - lr: 2.7542e-05\n",
            "Epoch 346/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 3.0283e-04 - accuracy: 0.9997 - val_loss: 2.2472e-04 - val_accuracy: 1.0000 - lr: 2.8184e-05\n",
            "Epoch 347/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.9630e-04 - accuracy: 0.9997 - val_loss: 2.1702e-04 - val_accuracy: 1.0000 - lr: 2.8840e-05\n",
            "Epoch 348/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.9206e-04 - accuracy: 0.9997 - val_loss: 2.2330e-04 - val_accuracy: 1.0000 - lr: 2.9512e-05\n",
            "Epoch 349/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.8043e-04 - accuracy: 0.9997 - val_loss: 2.2669e-04 - val_accuracy: 1.0000 - lr: 3.0200e-05\n",
            "Epoch 350/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.7959e-04 - accuracy: 0.9997 - val_loss: 2.0356e-04 - val_accuracy: 1.0000 - lr: 3.0903e-05\n",
            "Epoch 351/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.7556e-04 - accuracy: 0.9997 - val_loss: 2.0916e-04 - val_accuracy: 1.0000 - lr: 3.1623e-05\n",
            "Epoch 352/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.6934e-04 - accuracy: 0.9997 - val_loss: 2.0345e-04 - val_accuracy: 1.0000 - lr: 3.2359e-05\n",
            "Epoch 353/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.6274e-04 - accuracy: 0.9997 - val_loss: 1.9492e-04 - val_accuracy: 1.0000 - lr: 3.3113e-05\n",
            "Epoch 354/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.6100e-04 - accuracy: 0.9997 - val_loss: 1.8812e-04 - val_accuracy: 1.0000 - lr: 3.3884e-05\n",
            "Epoch 355/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.5552e-04 - accuracy: 0.9997 - val_loss: 1.8286e-04 - val_accuracy: 1.0000 - lr: 3.4674e-05\n",
            "Epoch 356/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.5071e-04 - accuracy: 0.9997 - val_loss: 1.7902e-04 - val_accuracy: 1.0000 - lr: 3.5481e-05\n",
            "Epoch 357/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.5016e-04 - accuracy: 0.9997 - val_loss: 1.7653e-04 - val_accuracy: 1.0000 - lr: 3.6308e-05\n",
            "Epoch 358/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.3939e-04 - accuracy: 0.9997 - val_loss: 1.7437e-04 - val_accuracy: 1.0000 - lr: 3.7154e-05\n",
            "Epoch 359/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 2.3693e-04 - accuracy: 0.9997 - val_loss: 1.7348e-04 - val_accuracy: 1.0000 - lr: 3.8019e-05\n",
            "Epoch 360/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 2.3403e-04 - accuracy: 0.9997 - val_loss: 1.7417e-04 - val_accuracy: 1.0000 - lr: 3.8905e-05\n",
            "Epoch 361/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 2.3318e-04 - accuracy: 0.9997 - val_loss: 1.6146e-04 - val_accuracy: 1.0000 - lr: 3.9811e-05\n",
            "Epoch 362/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.2641e-04 - accuracy: 0.9997 - val_loss: 1.7471e-04 - val_accuracy: 1.0000 - lr: 4.0738e-05\n",
            "Epoch 363/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.2065e-04 - accuracy: 0.9997 - val_loss: 1.5685e-04 - val_accuracy: 1.0000 - lr: 4.1687e-05\n",
            "Epoch 364/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.1460e-04 - accuracy: 0.9997 - val_loss: 1.5031e-04 - val_accuracy: 1.0000 - lr: 4.2658e-05\n",
            "Epoch 365/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.1155e-04 - accuracy: 0.9997 - val_loss: 1.5316e-04 - val_accuracy: 1.0000 - lr: 4.3652e-05\n",
            "Epoch 366/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.0940e-04 - accuracy: 0.9997 - val_loss: 1.4557e-04 - val_accuracy: 1.0000 - lr: 4.4668e-05\n",
            "Epoch 367/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.0823e-04 - accuracy: 0.9997 - val_loss: 1.4480e-04 - val_accuracy: 1.0000 - lr: 4.5709e-05\n",
            "Epoch 368/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 2.0266e-04 - accuracy: 0.9997 - val_loss: 1.3866e-04 - val_accuracy: 1.0000 - lr: 4.6774e-05\n",
            "Epoch 369/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.9819e-04 - accuracy: 0.9997 - val_loss: 1.4617e-04 - val_accuracy: 1.0000 - lr: 4.7863e-05\n",
            "Epoch 370/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.9723e-04 - accuracy: 0.9997 - val_loss: 1.3343e-04 - val_accuracy: 1.0000 - lr: 4.8978e-05\n",
            "Epoch 371/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.8953e-04 - accuracy: 0.9997 - val_loss: 1.3131e-04 - val_accuracy: 1.0000 - lr: 5.0119e-05\n",
            "Epoch 372/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.8634e-04 - accuracy: 0.9997 - val_loss: 1.3146e-04 - val_accuracy: 1.0000 - lr: 5.1286e-05\n",
            "Epoch 373/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.8950e-04 - accuracy: 0.9997 - val_loss: 1.2438e-04 - val_accuracy: 1.0000 - lr: 5.2481e-05\n",
            "Epoch 374/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.7873e-04 - accuracy: 0.9997 - val_loss: 1.2524e-04 - val_accuracy: 0.9996 - lr: 5.3703e-05\n",
            "Epoch 375/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.7668e-04 - accuracy: 0.9997 - val_loss: 1.2662e-04 - val_accuracy: 0.9996 - lr: 5.4954e-05\n",
            "Epoch 376/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.7341e-04 - accuracy: 0.9997 - val_loss: 1.1604e-04 - val_accuracy: 0.9996 - lr: 5.6234e-05\n",
            "Epoch 377/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.6762e-04 - accuracy: 0.9997 - val_loss: 1.1788e-04 - val_accuracy: 0.9996 - lr: 5.7544e-05\n",
            "Epoch 378/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.6728e-04 - accuracy: 0.9997 - val_loss: 1.1920e-04 - val_accuracy: 0.9996 - lr: 5.8884e-05\n",
            "Epoch 379/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.6151e-04 - accuracy: 0.9997 - val_loss: 1.2715e-04 - val_accuracy: 0.9996 - lr: 6.0256e-05\n",
            "Epoch 380/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.6082e-04 - accuracy: 0.9997 - val_loss: 1.1046e-04 - val_accuracy: 0.9996 - lr: 6.1659e-05\n",
            "Epoch 381/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.5379e-04 - accuracy: 0.9997 - val_loss: 1.2795e-04 - val_accuracy: 0.9996 - lr: 6.3096e-05\n",
            "Epoch 382/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.5755e-04 - accuracy: 0.9997 - val_loss: 1.0951e-04 - val_accuracy: 0.9996 - lr: 6.4565e-05\n",
            "Epoch 383/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.5001e-04 - accuracy: 0.9997 - val_loss: 1.1427e-04 - val_accuracy: 0.9996 - lr: 6.6069e-05\n",
            "Epoch 384/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 1.4633e-04 - accuracy: 0.9997 - val_loss: 1.1198e-04 - val_accuracy: 0.9996 - lr: 6.7608e-05\n",
            "Epoch 385/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.4407e-04 - accuracy: 0.9997 - val_loss: 1.0295e-04 - val_accuracy: 0.9996 - lr: 6.9183e-05\n",
            "Epoch 386/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.4084e-04 - accuracy: 0.9997 - val_loss: 1.4565e-04 - val_accuracy: 0.9996 - lr: 7.0795e-05\n",
            "Epoch 387/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.4210e-04 - accuracy: 0.9997 - val_loss: 1.0768e-04 - val_accuracy: 0.9996 - lr: 7.2444e-05\n",
            "Epoch 388/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.3620e-04 - accuracy: 0.9997 - val_loss: 1.0093e-04 - val_accuracy: 0.9996 - lr: 7.4131e-05\n",
            "Epoch 389/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.3228e-04 - accuracy: 0.9997 - val_loss: 1.0528e-04 - val_accuracy: 0.9996 - lr: 7.5858e-05\n",
            "Epoch 390/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 1.3242e-04 - accuracy: 0.9997 - val_loss: 9.8721e-05 - val_accuracy: 0.9996 - lr: 7.7625e-05\n",
            "Epoch 391/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.2792e-04 - accuracy: 0.9997 - val_loss: 1.0269e-04 - val_accuracy: 0.9996 - lr: 7.9433e-05\n",
            "Epoch 392/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.2905e-04 - accuracy: 0.9997 - val_loss: 9.7015e-05 - val_accuracy: 0.9996 - lr: 8.1283e-05\n",
            "Epoch 393/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 1.2351e-04 - accuracy: 0.9997 - val_loss: 9.6738e-05 - val_accuracy: 0.9996 - lr: 8.3176e-05\n",
            "Epoch 394/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.2254e-04 - accuracy: 0.9997 - val_loss: 1.2368e-04 - val_accuracy: 0.9996 - lr: 8.5114e-05\n",
            "Epoch 395/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.2053e-04 - accuracy: 0.9997 - val_loss: 1.0248e-04 - val_accuracy: 0.9996 - lr: 8.7096e-05\n",
            "Epoch 396/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.2120e-04 - accuracy: 0.9997 - val_loss: 9.9975e-05 - val_accuracy: 0.9996 - lr: 8.9125e-05\n",
            "Epoch 397/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.1440e-04 - accuracy: 0.9997 - val_loss: 9.4529e-05 - val_accuracy: 0.9996 - lr: 9.1201e-05\n",
            "Epoch 398/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 1.1126e-04 - accuracy: 0.9997 - val_loss: 9.3772e-05 - val_accuracy: 0.9996 - lr: 9.3325e-05\n",
            "Epoch 399/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 1.1222e-04 - accuracy: 0.9997 - val_loss: 9.5448e-05 - val_accuracy: 0.9996 - lr: 9.5499e-05\n",
            "Epoch 400/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 1.0919e-04 - accuracy: 0.9997 - val_loss: 9.6668e-05 - val_accuracy: 0.9996 - lr: 9.7724e-05\n",
            "Epoch 401/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 1.0625e-04 - accuracy: 0.9997 - val_loss: 1.0015e-04 - val_accuracy: 0.9996 - lr: 1.0000e-04\n",
            "Epoch 402/500\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 1.0771e-04 - accuracy: 0.9997 - val_loss: 1.0205e-04 - val_accuracy: 0.9996 - lr: 1.0233e-04\n",
            "Epoch 403/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.0318e-04 - accuracy: 0.9997 - val_loss: 1.0486e-04 - val_accuracy: 0.9996 - lr: 1.0471e-04\n",
            "Epoch 404/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.0382e-04 - accuracy: 0.9997 - val_loss: 9.8633e-05 - val_accuracy: 0.9996 - lr: 1.0715e-04\n",
            "Epoch 405/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.0004e-04 - accuracy: 0.9997 - val_loss: 1.0057e-04 - val_accuracy: 0.9996 - lr: 1.0965e-04\n",
            "Epoch 406/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 9.7981e-05 - accuracy: 0.9998 - val_loss: 9.4866e-05 - val_accuracy: 0.9996 - lr: 1.1220e-04\n",
            "Epoch 407/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 9.7822e-05 - accuracy: 0.9997 - val_loss: 1.0805e-04 - val_accuracy: 0.9996 - lr: 1.1482e-04\n",
            "Epoch 408/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 9.9758e-05 - accuracy: 0.9997 - val_loss: 1.0653e-04 - val_accuracy: 0.9996 - lr: 1.1749e-04\n",
            "Epoch 409/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 9.3419e-05 - accuracy: 0.9997 - val_loss: 1.4666e-04 - val_accuracy: 0.9996 - lr: 1.2023e-04\n",
            "Epoch 410/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 9.4970e-05 - accuracy: 0.9997 - val_loss: 9.6085e-05 - val_accuracy: 0.9996 - lr: 1.2303e-04\n",
            "Epoch 411/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.9057e-05 - accuracy: 0.9997 - val_loss: 1.0949e-04 - val_accuracy: 0.9996 - lr: 1.2589e-04\n",
            "Epoch 412/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.7031e-05 - accuracy: 0.9998 - val_loss: 1.0315e-04 - val_accuracy: 0.9996 - lr: 1.2882e-04\n",
            "Epoch 413/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 9.0196e-05 - accuracy: 0.9997 - val_loss: 9.9005e-05 - val_accuracy: 0.9996 - lr: 1.3183e-04\n",
            "Epoch 414/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 8.5526e-05 - accuracy: 0.9997 - val_loss: 1.0197e-04 - val_accuracy: 0.9996 - lr: 1.3490e-04\n",
            "Epoch 415/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.3391e-05 - accuracy: 0.9997 - val_loss: 1.1031e-04 - val_accuracy: 0.9996 - lr: 1.3804e-04\n",
            "Epoch 416/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.0866e-05 - accuracy: 0.9997 - val_loss: 9.9217e-05 - val_accuracy: 0.9996 - lr: 1.4125e-04\n",
            "Epoch 417/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 8.3221e-05 - accuracy: 0.9998 - val_loss: 1.0517e-04 - val_accuracy: 0.9996 - lr: 1.4454e-04\n",
            "Epoch 418/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.5708e-05 - accuracy: 0.9998 - val_loss: 1.1070e-04 - val_accuracy: 0.9996 - lr: 1.4791e-04\n",
            "Epoch 419/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.0422e-05 - accuracy: 0.9998 - val_loss: 1.2539e-04 - val_accuracy: 0.9996 - lr: 1.5136e-04\n",
            "Epoch 420/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.0861e-05 - accuracy: 0.9998 - val_loss: 1.1161e-04 - val_accuracy: 0.9996 - lr: 1.5488e-04\n",
            "Epoch 421/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.4678e-05 - accuracy: 0.9999 - val_loss: 1.0960e-04 - val_accuracy: 0.9996 - lr: 1.5849e-04\n",
            "Epoch 422/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.2113e-05 - accuracy: 0.9999 - val_loss: 1.3324e-04 - val_accuracy: 0.9996 - lr: 1.6218e-04\n",
            "Epoch 423/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.8420e-05 - accuracy: 0.9999 - val_loss: 1.0691e-04 - val_accuracy: 0.9996 - lr: 1.6596e-04\n",
            "Epoch 424/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.2695e-05 - accuracy: 0.9998 - val_loss: 1.1364e-04 - val_accuracy: 0.9996 - lr: 1.6982e-04\n",
            "Epoch 425/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.8760e-05 - accuracy: 0.9999 - val_loss: 1.2517e-04 - val_accuracy: 0.9996 - lr: 1.7378e-04\n",
            "Epoch 426/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.1532e-05 - accuracy: 0.9999 - val_loss: 1.2251e-04 - val_accuracy: 0.9996 - lr: 1.7783e-04\n",
            "Epoch 427/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.3204e-05 - accuracy: 0.9999 - val_loss: 1.0969e-04 - val_accuracy: 0.9996 - lr: 1.8197e-04\n",
            "Epoch 428/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.8239e-05 - accuracy: 0.9998 - val_loss: 1.1079e-04 - val_accuracy: 0.9996 - lr: 1.8621e-04\n",
            "Epoch 429/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 6.9957e-05 - accuracy: 0.9999 - val_loss: 1.1317e-04 - val_accuracy: 0.9996 - lr: 1.9055e-04\n",
            "Epoch 430/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.2588e-05 - accuracy: 0.9999 - val_loss: 1.1621e-04 - val_accuracy: 0.9996 - lr: 1.9498e-04\n",
            "Epoch 431/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.3019e-05 - accuracy: 0.9999 - val_loss: 1.0913e-04 - val_accuracy: 0.9996 - lr: 1.9953e-04\n",
            "Epoch 432/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.1017e-05 - accuracy: 0.9999 - val_loss: 1.2668e-04 - val_accuracy: 0.9996 - lr: 2.0417e-04\n",
            "Epoch 433/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.5667e-05 - accuracy: 0.9999 - val_loss: 1.2705e-04 - val_accuracy: 0.9996 - lr: 2.0893e-04\n",
            "Epoch 434/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.8285e-05 - accuracy: 0.9999 - val_loss: 1.2120e-04 - val_accuracy: 0.9996 - lr: 2.1380e-04\n",
            "Epoch 435/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.4726e-05 - accuracy: 0.9998 - val_loss: 1.1339e-04 - val_accuracy: 0.9996 - lr: 2.1878e-04\n",
            "Epoch 436/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.9168e-05 - accuracy: 0.9999 - val_loss: 1.3063e-04 - val_accuracy: 0.9996 - lr: 2.2387e-04\n",
            "Epoch 437/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.4861e-05 - accuracy: 0.9999 - val_loss: 1.6227e-04 - val_accuracy: 0.9996 - lr: 2.2909e-04\n",
            "Epoch 438/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.0680e-05 - accuracy: 0.9999 - val_loss: 2.1393e-04 - val_accuracy: 0.9996 - lr: 2.3442e-04\n",
            "Epoch 439/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.5843e-05 - accuracy: 0.9999 - val_loss: 1.2905e-04 - val_accuracy: 0.9996 - lr: 2.3988e-04\n",
            "Epoch 440/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.9608e-05 - accuracy: 0.9999 - val_loss: 1.4092e-04 - val_accuracy: 0.9996 - lr: 2.4547e-04\n",
            "Epoch 441/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.0827e-05 - accuracy: 0.9999 - val_loss: 1.4174e-04 - val_accuracy: 0.9996 - lr: 2.5119e-04\n",
            "Epoch 442/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.3421e-05 - accuracy: 0.9999 - val_loss: 1.2938e-04 - val_accuracy: 0.9996 - lr: 2.5704e-04\n",
            "Epoch 443/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.8222e-05 - accuracy: 0.9999 - val_loss: 1.4086e-04 - val_accuracy: 0.9996 - lr: 2.6303e-04\n",
            "Epoch 444/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.3427e-05 - accuracy: 0.9999 - val_loss: 1.3651e-04 - val_accuracy: 0.9996 - lr: 2.6915e-04\n",
            "Epoch 445/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 6.0437e-05 - accuracy: 0.9999 - val_loss: 1.4916e-04 - val_accuracy: 0.9996 - lr: 2.7542e-04\n",
            "Epoch 446/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.0341e-05 - accuracy: 0.9999 - val_loss: 1.3827e-04 - val_accuracy: 0.9996 - lr: 2.8184e-04\n",
            "Epoch 447/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.4613e-05 - accuracy: 0.9999 - val_loss: 1.8858e-04 - val_accuracy: 0.9996 - lr: 2.8840e-04\n",
            "Epoch 448/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.2142e-05 - accuracy: 0.9999 - val_loss: 1.5968e-04 - val_accuracy: 0.9996 - lr: 2.9512e-04\n",
            "Epoch 449/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.2498e-05 - accuracy: 0.9999 - val_loss: 1.6346e-04 - val_accuracy: 0.9996 - lr: 3.0200e-04\n",
            "Epoch 450/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.8798e-05 - accuracy: 0.9999 - val_loss: 2.2008e-04 - val_accuracy: 0.9996 - lr: 3.0903e-04\n",
            "Epoch 451/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.9220e-05 - accuracy: 0.9999 - val_loss: 1.4388e-04 - val_accuracy: 0.9996 - lr: 3.1623e-04\n",
            "Epoch 452/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 5.8607e-05 - accuracy: 0.9999 - val_loss: 1.8928e-04 - val_accuracy: 0.9996 - lr: 3.2359e-04\n",
            "Epoch 453/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.9116e-05 - accuracy: 0.9999 - val_loss: 1.3953e-04 - val_accuracy: 0.9996 - lr: 3.3113e-04\n",
            "Epoch 454/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.4057e-05 - accuracy: 0.9999 - val_loss: 1.3993e-04 - val_accuracy: 0.9996 - lr: 3.3884e-04\n",
            "Epoch 455/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.2683e-05 - accuracy: 0.9999 - val_loss: 1.4969e-04 - val_accuracy: 0.9996 - lr: 3.4674e-04\n",
            "Epoch 456/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 6.9329e-05 - accuracy: 0.9999 - val_loss: 1.5220e-04 - val_accuracy: 0.9996 - lr: 3.5481e-04\n",
            "Epoch 457/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.2660e-05 - accuracy: 0.9999 - val_loss: 1.5522e-04 - val_accuracy: 0.9996 - lr: 3.6308e-04\n",
            "Epoch 458/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.6100e-05 - accuracy: 0.9999 - val_loss: 1.5259e-04 - val_accuracy: 0.9996 - lr: 3.7154e-04\n",
            "Epoch 459/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 6.7567e-05 - accuracy: 0.9999 - val_loss: 1.7007e-04 - val_accuracy: 0.9996 - lr: 3.8019e-04\n",
            "Epoch 460/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.1006e-05 - accuracy: 0.9999 - val_loss: 1.7311e-04 - val_accuracy: 0.9996 - lr: 3.8905e-04\n",
            "Epoch 461/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.5288e-05 - accuracy: 0.9999 - val_loss: 1.7652e-04 - val_accuracy: 0.9996 - lr: 3.9811e-04\n",
            "Epoch 462/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 6.7766e-05 - accuracy: 0.9999 - val_loss: 1.5169e-04 - val_accuracy: 0.9996 - lr: 4.0738e-04\n",
            "Epoch 463/500\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 5.1225e-05 - accuracy: 0.9999 - val_loss: 1.4725e-04 - val_accuracy: 0.9996 - lr: 4.1687e-04\n",
            "Epoch 464/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.5626e-05 - accuracy: 0.9999 - val_loss: 3.0273e-04 - val_accuracy: 0.9996 - lr: 4.2658e-04\n",
            "Epoch 465/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.5759e-05 - accuracy: 0.9999 - val_loss: 1.6392e-04 - val_accuracy: 0.9996 - lr: 4.3652e-04\n",
            "Epoch 466/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.4583e-05 - accuracy: 0.9999 - val_loss: 1.5762e-04 - val_accuracy: 0.9996 - lr: 4.4668e-04\n",
            "Epoch 467/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.2549e-05 - accuracy: 0.9999 - val_loss: 1.6357e-04 - val_accuracy: 0.9996 - lr: 4.5709e-04\n",
            "Epoch 468/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.0288e-05 - accuracy: 0.9999 - val_loss: 1.7019e-04 - val_accuracy: 0.9996 - lr: 4.6774e-04\n",
            "Epoch 469/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.1344e-05 - accuracy: 0.9999 - val_loss: 1.4353e-04 - val_accuracy: 0.9996 - lr: 4.7863e-04\n",
            "Epoch 470/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.6122e-05 - accuracy: 0.9999 - val_loss: 1.5378e-04 - val_accuracy: 0.9996 - lr: 4.8978e-04\n",
            "Epoch 471/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.9610e-05 - accuracy: 0.9999 - val_loss: 1.8872e-04 - val_accuracy: 0.9996 - lr: 5.0119e-04\n",
            "Epoch 472/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.5907e-05 - accuracy: 0.9999 - val_loss: 1.6762e-04 - val_accuracy: 0.9996 - lr: 5.1286e-04\n",
            "Epoch 473/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 9.3952e-05 - accuracy: 0.9999 - val_loss: 2.1154e-04 - val_accuracy: 0.9996 - lr: 5.2481e-04\n",
            "Epoch 474/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 8.5193e-05 - accuracy: 0.9999 - val_loss: 1.6206e-04 - val_accuracy: 0.9996 - lr: 5.3703e-04\n",
            "Epoch 475/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.7231e-05 - accuracy: 0.9999 - val_loss: 1.4369e-04 - val_accuracy: 0.9996 - lr: 5.4954e-04\n",
            "Epoch 476/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.8239e-05 - accuracy: 0.9999 - val_loss: 1.9844e-04 - val_accuracy: 0.9996 - lr: 5.6234e-04\n",
            "Epoch 477/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.0549e-04 - accuracy: 0.9999 - val_loss: 1.4044e-04 - val_accuracy: 0.9996 - lr: 5.7544e-04\n",
            "Epoch 478/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.8329e-05 - accuracy: 0.9999 - val_loss: 1.5178e-04 - val_accuracy: 0.9996 - lr: 5.8884e-04\n",
            "Epoch 479/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.4952e-05 - accuracy: 0.9999 - val_loss: 1.3673e-04 - val_accuracy: 0.9996 - lr: 6.0256e-04\n",
            "Epoch 480/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.6260e-05 - accuracy: 0.9999 - val_loss: 1.5321e-04 - val_accuracy: 0.9996 - lr: 6.1659e-04\n",
            "Epoch 481/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.9640e-05 - accuracy: 0.9999 - val_loss: 1.7905e-04 - val_accuracy: 0.9996 - lr: 6.3096e-04\n",
            "Epoch 482/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.0051e-05 - accuracy: 0.9999 - val_loss: 1.6676e-04 - val_accuracy: 0.9996 - lr: 6.4565e-04\n",
            "Epoch 483/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.9595e-05 - accuracy: 0.9999 - val_loss: 1.7413e-04 - val_accuracy: 0.9996 - lr: 6.6069e-04\n",
            "Epoch 484/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.4072e-05 - accuracy: 0.9999 - val_loss: 1.4091e-04 - val_accuracy: 0.9996 - lr: 6.7608e-04\n",
            "Epoch 485/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.0872e-05 - accuracy: 0.9999 - val_loss: 1.9981e-04 - val_accuracy: 0.9996 - lr: 6.9183e-04\n",
            "Epoch 486/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.5181e-05 - accuracy: 0.9999 - val_loss: 1.7381e-04 - val_accuracy: 0.9996 - lr: 7.0795e-04\n",
            "Epoch 487/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.8497e-05 - accuracy: 0.9999 - val_loss: 1.9886e-04 - val_accuracy: 0.9996 - lr: 7.2444e-04\n",
            "Epoch 488/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 4.8860e-05 - accuracy: 0.9999 - val_loss: 1.4585e-04 - val_accuracy: 0.9996 - lr: 7.4131e-04\n",
            "Epoch 489/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 7.7853e-05 - accuracy: 0.9999 - val_loss: 1.2102e-04 - val_accuracy: 0.9996 - lr: 7.5858e-04\n",
            "Epoch 490/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.4594e-05 - accuracy: 0.9999 - val_loss: 1.5308e-04 - val_accuracy: 0.9996 - lr: 7.7625e-04\n",
            "Epoch 491/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.1752e-05 - accuracy: 0.9999 - val_loss: 1.4507e-04 - val_accuracy: 0.9996 - lr: 7.9433e-04\n",
            "Epoch 492/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.3556e-05 - accuracy: 0.9999 - val_loss: 1.8640e-04 - val_accuracy: 0.9996 - lr: 8.1283e-04\n",
            "Epoch 493/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.7161e-05 - accuracy: 0.9999 - val_loss: 2.5340e-04 - val_accuracy: 0.9996 - lr: 8.3176e-04\n",
            "Epoch 494/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 6.3785e-05 - accuracy: 0.9999 - val_loss: 1.2893e-04 - val_accuracy: 0.9996 - lr: 8.5114e-04\n",
            "Epoch 495/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 1.1450e-04 - accuracy: 0.9999 - val_loss: 1.4436e-04 - val_accuracy: 0.9996 - lr: 8.7096e-04\n",
            "Epoch 496/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.4136e-05 - accuracy: 0.9999 - val_loss: 1.5906e-04 - val_accuracy: 0.9996 - lr: 8.9125e-04\n",
            "Epoch 497/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.3314e-05 - accuracy: 0.9998 - val_loss: 1.5607e-04 - val_accuracy: 0.9996 - lr: 9.1201e-04\n",
            "Epoch 498/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.8968e-05 - accuracy: 0.9999 - val_loss: 2.7283e-04 - val_accuracy: 0.9996 - lr: 9.3325e-04\n",
            "Epoch 499/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.4801e-05 - accuracy: 0.9999 - val_loss: 1.5822e-04 - val_accuracy: 0.9996 - lr: 9.5499e-04\n",
            "Epoch 500/500\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 5.4059e-05 - accuracy: 1.0000 - val_loss: 1.7278e-04 - val_accuracy: 0.9996 - lr: 9.7724e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "URUiKblXq2we",
        "outputId": "82acef43-6392-4076-bd1b-89b9e4b98c34"
      },
      "source": [
        "lr_param = history.history[\"lr\"]\n",
        "loss_param = history.history[\"loss\"]\n",
        "\n",
        "plt.semilogx(lr_param, loss_param)\n",
        "#plt.xlim(1e-8, 1e-1)\n",
        "plt.ylim(0,.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 0.3)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI-FqIJE3UGL"
      },
      "source": [
        "from the graph, we can see that learning rate 1e-5 is pretty good, so we gonna use it to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqlbvUClq2sT",
        "outputId": "4a5e0a85-b234-4aea-851f-46664ab46a93"
      },
      "source": [
        "METRICS = [\n",
        "           tf.keras.metrics.BinaryAccuracy(name='accuracy', \n",
        "                                           threshold=0.5),\n",
        "          ]\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.compile(optimizer=optimizer,                                                   \n",
        "                loss=tf.keras.losses.Huber(),\n",
        "                metrics=METRICS)\n",
        "\n",
        "history = model.fit(train_data,batch_size=100,\n",
        "                      epochs=100,validation_data=val_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               2304      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,521\n",
            "Trainable params: 43,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 0.1884 - accuracy: 0.6069 - val_loss: 0.1729 - val_accuracy: 0.6069\n",
            "Epoch 2/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1588 - accuracy: 0.6069 - val_loss: 0.1484 - val_accuracy: 0.6069\n",
            "Epoch 3/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1382 - accuracy: 0.6069 - val_loss: 0.1308 - val_accuracy: 0.6069\n",
            "Epoch 4/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1192 - accuracy: 0.6069 - val_loss: 0.1121 - val_accuracy: 0.6069\n",
            "Epoch 5/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.1027 - accuracy: 0.6128 - val_loss: 0.0965 - val_accuracy: 0.6711\n",
            "Epoch 6/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0870 - accuracy: 0.7567 - val_loss: 0.0804 - val_accuracy: 0.8148\n",
            "Epoch 7/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.8367 - val_loss: 0.0625 - val_accuracy: 0.8491\n",
            "Epoch 8/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.8696 - val_loss: 0.0491 - val_accuracy: 0.8769\n",
            "Epoch 9/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.8931 - val_loss: 0.0385 - val_accuracy: 0.8906\n",
            "Epoch 10/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 0.9047 - val_loss: 0.0312 - val_accuracy: 0.9007\n",
            "Epoch 11/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9135 - val_loss: 0.0264 - val_accuracy: 0.9097\n",
            "Epoch 12/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9215 - val_loss: 0.0229 - val_accuracy: 0.9191\n",
            "Epoch 13/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9292 - val_loss: 0.0202 - val_accuracy: 0.9289\n",
            "Epoch 14/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9354 - val_loss: 0.0180 - val_accuracy: 0.9343\n",
            "Epoch 15/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9423 - val_loss: 0.0161 - val_accuracy: 0.9397\n",
            "Epoch 16/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9490 - val_loss: 0.0145 - val_accuracy: 0.9473\n",
            "Epoch 17/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9549 - val_loss: 0.0131 - val_accuracy: 0.9560\n",
            "Epoch 18/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9604 - val_loss: 0.0119 - val_accuracy: 0.9639\n",
            "Epoch 19/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9688 - val_loss: 0.0108 - val_accuracy: 0.9726\n",
            "Epoch 20/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9782 - val_loss: 0.0098 - val_accuracy: 0.9845\n",
            "Epoch 21/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 0.9895 - val_loss: 0.0089 - val_accuracy: 0.9931\n",
            "Epoch 22/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9997 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9997 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9997 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.8425e-04 - accuracy: 0.9997 - val_loss: 9.4393e-04 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 9.0604e-04 - accuracy: 0.9997 - val_loss: 8.6917e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 8.4594e-04 - accuracy: 0.9997 - val_loss: 8.1368e-04 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.9926e-04 - accuracy: 0.9997 - val_loss: 7.7274e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.6078e-04 - accuracy: 0.9997 - val_loss: 7.3344e-04 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.3007e-04 - accuracy: 0.9997 - val_loss: 7.1431e-04 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 7.0485e-04 - accuracy: 0.9997 - val_loss: 6.7533e-04 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.8615e-04 - accuracy: 0.9997 - val_loss: 6.5920e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.6488e-04 - accuracy: 0.9997 - val_loss: 6.3492e-04 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.4964e-04 - accuracy: 0.9997 - val_loss: 6.2663e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.3630e-04 - accuracy: 0.9997 - val_loss: 6.1216e-04 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.2232e-04 - accuracy: 0.9997 - val_loss: 5.9263e-04 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 6.0787e-04 - accuracy: 0.9997 - val_loss: 5.7551e-04 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.9437e-04 - accuracy: 0.9997 - val_loss: 5.5857e-04 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.8363e-04 - accuracy: 0.9997 - val_loss: 5.4652e-04 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.7140e-04 - accuracy: 0.9997 - val_loss: 5.3507e-04 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.5882e-04 - accuracy: 0.9997 - val_loss: 5.2118e-04 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.5053e-04 - accuracy: 0.9997 - val_loss: 5.0946e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.3907e-04 - accuracy: 0.9997 - val_loss: 5.0134e-04 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.3124e-04 - accuracy: 0.9997 - val_loss: 4.8934e-04 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.2252e-04 - accuracy: 0.9997 - val_loss: 5.0417e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 5.1119e-04 - accuracy: 0.9997 - val_loss: 4.6251e-04 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.9767e-04 - accuracy: 0.9997 - val_loss: 4.5542e-04 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.8723e-04 - accuracy: 0.9997 - val_loss: 4.4440e-04 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.8272e-04 - accuracy: 0.9997 - val_loss: 4.3551e-04 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.7418e-04 - accuracy: 0.9997 - val_loss: 4.3833e-04 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.6676e-04 - accuracy: 0.9997 - val_loss: 4.1977e-04 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.5685e-04 - accuracy: 0.9997 - val_loss: 4.0880e-04 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.4804e-04 - accuracy: 0.9997 - val_loss: 4.0477e-04 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.4273e-04 - accuracy: 0.9997 - val_loss: 3.9550e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.3614e-04 - accuracy: 0.9997 - val_loss: 3.8801e-04 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.2959e-04 - accuracy: 0.9997 - val_loss: 3.8152e-04 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.2329e-04 - accuracy: 0.9997 - val_loss: 3.7219e-04 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.1731e-04 - accuracy: 0.9997 - val_loss: 3.6796e-04 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 4.1145e-04 - accuracy: 0.9997 - val_loss: 3.6034e-04 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.0555e-04 - accuracy: 0.9997 - val_loss: 3.5340e-04 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 4.0072e-04 - accuracy: 0.9997 - val_loss: 3.6502e-04 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.9513e-04 - accuracy: 0.9997 - val_loss: 3.4857e-04 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.8956e-04 - accuracy: 0.9997 - val_loss: 3.3403e-04 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.8484e-04 - accuracy: 0.9997 - val_loss: 3.3426e-04 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.7975e-04 - accuracy: 0.9997 - val_loss: 3.2670e-04 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.7371e-04 - accuracy: 0.9997 - val_loss: 3.3041e-04 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.6905e-04 - accuracy: 0.9997 - val_loss: 3.2186e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.6321e-04 - accuracy: 0.9997 - val_loss: 3.0942e-04 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "111/111 [==============================] - 1s 4ms/step - loss: 3.5866e-04 - accuracy: 0.9997 - val_loss: 3.1063e-04 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.5589e-04 - accuracy: 0.9997 - val_loss: 3.0216e-04 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.5123e-04 - accuracy: 0.9997 - val_loss: 2.9846e-04 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.4570e-04 - accuracy: 0.9997 - val_loss: 3.0413e-04 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "111/111 [==============================] - 1s 5ms/step - loss: 3.4337e-04 - accuracy: 0.9997 - val_loss: 2.8643e-04 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.3958e-04 - accuracy: 0.9997 - val_loss: 2.9146e-04 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.3316e-04 - accuracy: 0.9997 - val_loss: 2.7759e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.3070e-04 - accuracy: 0.9997 - val_loss: 2.7318e-04 - val_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.2809e-04 - accuracy: 0.9997 - val_loss: 2.7164e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.2188e-04 - accuracy: 0.9997 - val_loss: 2.6661e-04 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.1865e-04 - accuracy: 0.9997 - val_loss: 2.6298e-04 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.1552e-04 - accuracy: 0.9997 - val_loss: 2.5997e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.1262e-04 - accuracy: 0.9997 - val_loss: 2.5582e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.0740e-04 - accuracy: 0.9997 - val_loss: 2.6254e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.0382e-04 - accuracy: 0.9997 - val_loss: 2.5199e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 3.0283e-04 - accuracy: 0.9997 - val_loss: 2.4428e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "111/111 [==============================] - 0s 4ms/step - loss: 2.9821e-04 - accuracy: 0.9997 - val_loss: 2.3940e-04 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucasnkkc3g6F"
      },
      "source": [
        "Visualize the result!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "4vNxu3D-q2ju",
        "outputId": "e5a2fa6a-8cda-45e8-a466-a936ebecc74d"
      },
      "source": [
        "epoch_param = history.epoch\n",
        "loss_param = history.history[\"loss\"]\n",
        "val_loss_param = history.history[\"val_loss\"]\n",
        "acc_param = history.history[\"accuracy\"]\n",
        "val_acc_param = history.history[\"val_accuracy\"]\n",
        "\n",
        "\n",
        "plt.plot(epoch_param, loss_param,label = \"train_loss\")\n",
        "plt.plot(epoch_param, val_loss_param, label =\"validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"loss\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(epoch_param, acc_param, label = \"train_accuracy\")\n",
        "plt.plot(epoch_param, val_acc_param, label = \"validation_accuracy\")\n",
        "plt.title(\"accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-ANgza03kjY"
      },
      "source": [
        "We see that the model has converged perfectly!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKVLFpSo3tzr"
      },
      "source": [
        "As we know, the dataset is unbalanced. So we need to evaluate the performance based on f1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAPs5mYrq2Uo"
      },
      "source": [
        "def compute_metrics(X,y):\n",
        "  y_pred = model.predict(X)\n",
        "  y_pred = y_pred >= 0.5\n",
        "  y_pred = y_pred.astype('int')\n",
        "  cm = confusion_matrix(y, y_pred)\n",
        "\n",
        "  print(\"accuracy:\", accuracy_score(y, y_pred))\n",
        "  print(\"precision:\", precision_score(y, y_pred))\n",
        "  print(\"recall:\", recall_score(y, y_pred))\n",
        "  print(\"f1 score:\", f1_score(y, y_pred))\n",
        "  print(\"True Positive:\", cm[1][1])\n",
        "  print(\"True Negative:\", cm[0][0])\n",
        "  print(\"False Positive:\", cm[0][1])\n",
        "  print(\"False Negative:\", cm[1][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjrnOwsA04Ub",
        "outputId": "5bd8f419-35af-41a0-d24c-25704cf14344"
      },
      "source": [
        "compute_metrics(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.9997291685474406\n",
            "precision: 1.0\n",
            "recall: 0.9993109784106569\n",
            "f1 score: 0.9996553704767375\n",
            "True Positive: 4351\n",
            "True Negative: 6723\n",
            "False Positive: 0\n",
            "False Negative: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0PSSWXg04OM",
        "outputId": "f18870f0-c7fc-4302-abdf-ee4eedb545e4"
      },
      "source": [
        "compute_metrics(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 1.0\n",
            "precision: 1.0\n",
            "recall: 1.0\n",
            "f1 score: 1.0\n",
            "True Positive: 1089\n",
            "True Negative: 1681\n",
            "False Positive: 0\n",
            "False Negative: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL68l1xP33cA"
      },
      "source": [
        "Yeay! our model has an amazing performance. The f1 score is more than 0.999 for both train and test data.\n",
        "We can conclude that our model can predict with great accuracy and able to generalize as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bqo5FxRLarU"
      },
      "source": [
        "Finally, Save the model and the scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0fp3p-U4vYw"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/CAD IT/Q1.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnVuyvPVAXTM"
      },
      "source": [
        "from pickle import dump\n",
        "dump(X_Scaler, open('/content/drive/MyDrive/CAD IT/scaler.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}